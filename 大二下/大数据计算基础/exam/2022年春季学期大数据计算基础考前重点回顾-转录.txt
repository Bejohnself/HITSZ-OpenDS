file: 上.mp3
***********************************result**************************************
[0:53.000,0:55.180]  好，那个同学们下午好。
[0:55.200,0:56.480]  嗯。
[0:56.480,1:2.200]  我刚才在群里也发了啊，就是还是说一下那个周五那个大作业。
[1:2.300,1:4.340]  和那个实验的事情啊。
[1:4.460,1:6.400]  那个。
[1:6.400,1:10.420]  因为最后是要每个组啊，在这个实验平台上。
[1:10.420,1:11.220]  的。
[1:11.220,1:16.140]  一个我们就是三个节点，那个机器上来做，因为大家硬件都一样啊。
[1:16.320,1:18.580]  那么同时也是为了。
[1:18.580,1:22.000]  怕就就是登进来有干扰，所以。
[1:22.000,1:27.980]  我们之前会把那个环境，就是你们现在用的这些环境关掉啊。
[1:27.980,1:29.580]  其实当时那个环境。
[1:29.580,1:40.620]  嗯，平常你每次进去也是新的嘛，但是你自己可能如果有在在他里面放了东西的呀，你的程序啊，就是特别提醒你赶快，你要把它弄下来啊。
[1:40.620,1:43.220]  在周五上午之前弄下来。
[1:43.220,1:46.040]  免得你这个东西丢掉啊这个是。
[1:46.100,1:47.420]  呃。
[1:47.900,1:52.520]  呃，史诗丢掉了？那，那那很很很可惜了，你工作白干了。
[1:52.800,2:2.340]  这个清楚吧，可能你也你也不一定在那里有备份啊，你不在那备份，当然没这个关系啊，但是如果有的同学在他里面备份了。
[2:2.420,2:7.480]  是就要记得把它弄过来，然后到周五下午的时候。
[2:7.480,2:16.520]  先是这个a组的吗，A组的一二班的啊，到时候就每个组一个账号，你们组里面找一个人啊。
[2:16.520,2:20.180]  然后你们可以坐在一起吧，做做靠近来就是一起参谋着。
[2:20.180,2:24.520]  因为真正运行的时候是每个组就是一个代表登进去。
[2:24.520,2:26.100]  那么那个环境。
[2:26.380,2:33.040]  其他跟你们现在用的都是一样的，只不过里面还有数据啊，我们是把那个数据也打包到里面去了。
[2:33.080,2:43.320]  数据的话就是那个手机漫游的那个信息啊，我我不是给了个样例吗，那么实际的是一个8G的一个文件。
[2:43.320,2:46.200]  八吉字节啊，里面是有两一条记录啊。
[2:46.200,2:48.160]  这是你们要在里面。
[2:48.160,2:50.340]  里面找着这个其实。
[2:50.340,2:53.160]  也不多，这可能是一个。
[2:53.160,2:56.320]  一个几百万人口的啊一个。
[2:56.320,3:1.300]  城市里面的啊，漫游一天的啊，一天的漫游的，大概的情况。
[3:1.540,3:2.780]  嗯。
[3:2.820,3:9.540]  但是有还有一点不同，就是给你们每个组的，不是有一个就是感染人的那个列表吗。
[3:9.540,3:12.620]  就是那个小文件，每个组是不一样的啊。
[3:12.760,3:27.380]  就是，所以这但对程序上每个组是不一样的，所以你们主做你们自己的就就可以，这里当然的文件名就有点不同，文件名，现在在那个infected后面是带了那个a。
[3:27.380,3:30.960]  A01A02，带了主号的啊，你们自己。
[3:30.960,3:35.380]  注意一下，如果你们的程序还是用的那个文件名，你把那个文件。
[3:35.380,3:37.240]  下来改一下啊。
[3:37.860,3:43.460]  那么这个文件的给法就在这里，也是为了做到公平，在这里还是有个步骤。
[3:43.460,3:51.300]  就是给你们环境之后，因为这个环境加载啊，他又带了一些数据，可能要些时间各种就不一样啊。
[3:51.300,3:56.040]  所以呢他差的不大，但是为了就是公平，就是这个时候。
[3:56.060,4:1.480]  开始啦，把这个数据给你们，你们都把这个环境加载起起来。
[4:1.480,4:3.860]  大家都说都起起来了之后。
[4:3.860,4:13.340]  这个时候下一步就是统一告诉你们去下载那个赶那个感染那个文件很小嘛，那里面就就还是每每个里面就十个。
[4:13.380,4:15.340]  就十个这个。
[4:15.480,4:21.880]  呃感染人啊，那么这个下发当然就是同意开始了，然后提交。
[4:21.880,4:26.580]  你的结果出来大家还都清楚吧，提交时你把那个文件做出来。
[4:26.580,4:33.140]  第一个就是那个普遍感染的，这是最核心的这个啊，首先你要把这个就是不分那个时间。
[4:33.140,4:36.880]  这个排除的，你做完了就赶快发到微信群里。
[4:37.040,4:42.420]  那个名字一定要按我那个里面要求的那个什么入mark。
[4:42.420,4:46.120]  完了把那特别你的主号，你要给写对了，否则那么。
[4:46.120,4:50.020]  就是十几个组发出来，我还分不出是哪个组的。
[4:50.020,4:55.780]  所以为了让达到这一点，你的主号你这个文件名错了，我就不认得啊，就你们组还没发啊。
[4:55.780,4:57.420]  这个是。
[4:57.420,5:1.380]  这个是大家要注意的，发的话其实要快一点。
[5:1.380,5:7.680]  可能有个办法就是你可以在这个平台里面登录微信网页版。
[5:7.680,5:11.320]  反正我试了一下是可以登进去的，你们这些也可以试一下。
[5:11.340,5:15.320]  这样子就会快一点啊，就是微信网页版。
[5:15.320,5:21.280]  你扫码登进来的话，那你只要因为你你做完了肯定是先是在你的这个。
[5:21.280,5:25.280]  这个实验平台的这个本地嘛，那么你从这里直接就可以把它。
[5:25.280,5:26.200]  发出去了啊。
[5:26.560,5:28.040]  就是。
[5:28.100,5:31.420]  就关于这个实验啊，就是。
[5:31.560,5:33.220]  说这么多吧。
[5:34.000,5:35.240]  那么。
[5:35.340,5:39.380]  嗯，还有呢，就是关于考试啊考试的。
[5:39.380,5:40.200]  题型。
[5:40.200,5:46.560]  期末考试的题型就是单选、多选、简答和综合啊。
[5:46.560,5:48.460]  那么单选多选。
[5:48.460,5:49.380]  是50。
[5:49.620,5:52.380]  五五十分完了简答。
[5:52.720,5:58.660]  三十八一个综合题，其实也是类似问答的题啊，就更综合的问答题20分。
[5:58.660,6:0.200]  啊，是大概。
[6:0.200,6:2.500]  就是这样的一个。
[6:2.500,6:3.680]  一个分部啊。
[6:3.720,6:8.460]  那个单选多选里面啊，你们特别是前以前做的那个。
[6:8.460,6:13.300]  那个练习啊什么的还没做的呀，你赶快就去做完了啊那个肯定是。
[6:13.300,6:14.460]  有用的啊。
[6:16.040,6:17.140]  嗯。
[6:17.640,6:19.420]  好，那么。
[6:19.520,6:23.860]  下面我们就开始啊，就是这最后课，其实就是。
[6:23.860,6:28.600]  把各章啊给大家在整个就总结一下啊，来串一下。
[6:28.600,6:31.680]  就是看看这个，我们叫。
[6:31.680,6:35.100]  大数据计算基础嘛，啊那么我们。
[6:35.100,6:36.020]  嗯。
[6:39.540,6:40.780]  嗯。
[6:41.400,6:45.580]  先是这个大数据概述啊，第一张啊，那么。
[6:45.580,6:54.220]  它里面有其实就是引入了这个什么是大数据啊，大数据时代怎么到来的呀，这个发展的。
[6:54.220,6:56.680]  这么一些一些过程啊。
[6:56.680,6:59.300]  啊，在哪些领域有应用啊。
[6:59.300,7:2.060]  那么这张是一个。
[7:2.060,7:3.320]  就是。
[7:3.520,7:7.780]  破冰啊，大家建立概念的这么一张一个章节。
[7:7.780,7:9.560]  那在这里面啊。
[7:9.680,7:16.500]  比较注意的就是什么什么是大数据啊，那么它是用了这个思维啊，因为这个大数据也说过。
[7:16.500,7:18.240]  其实还是没有一个。
[7:18.240,7:21.000]  很精确的定义啊，但是起码有点大啊。
[7:21.000,7:22.540]  那么这个思维。
[7:22.540,7:26.560]  可以代表啊对这个大数据的一个感受。
[7:26.560,7:29.020]  我不知道现在学完这么多了啊但是。
[7:29.020,7:32.340]  大家对大数据是个什么东西，是不是？
[7:32.340,7:36.440]  基本上还是能有一定的这个概念了，一个这个事情。
[7:37.260,7:44.460]  这一个问题啊是不是有，有没有关于大数据啊，这个大家能做初步的这个判断了啊。
[7:44.460,7:50.820]  那么当然这个思维里面就是这个数据量大啊，种类繁多啊这是。
[7:50.820,7:54.780]  这是最基本的啊，就是他确实是大大到了。
[7:54.780,7:56.360]  这个程度当然。
[7:56.540,8:0.080]  不，不一样了，大家都都用过一个。
[8:0.080,8:3.320]  呃，就是各种电影都用过，就是大道。
[8:3.320,8:4.300]  嗯。
[8:4.300,8:9.200]  当前当然说那个定义的时候啊，其实就是传统的这个计算机。
[8:9.200,8:13.140]  传统的那种单机体系的这样的计算机。
[8:13.140,8:16.940]  是不能处理的这个程度啊大概是。
[8:16.940,8:20.100]  那么这个其实我们从从。
[8:20.100,8:22.600]  量级上来看啊就是。
[8:22.720,8:24.100]  嗯。
[8:25.220,8:33.580]  你可能得起码什么P的啊，什么什么P的啊，就是可能得到得到这样的这样的量级啊。
[8:33.580,8:34.720]  但是。
[8:34.720,8:36.600]  那个，呃。
[8:36.600,8:37.700]  处理的。
[8:37.940,8:44.660]  当然相应的，对这些东西要求处理的速度就就非常快啊，因为PRT这样的量级。
[8:44.660,8:48.720]  当然你现在说一个TB的这么一个数据啊。
[8:49.260,8:55.180]  那么其实你如果要求处理的很快的话，那么单击也是。
[8:55.180,9:1.080]  也是这个有问题的啊，因为我们学了这些应该知道啊，这个计算机。
[9:1.080,9:8.840]  他受他的这个就是cpu的能力啊，内存的能力啊，就是这些东西的这些制约啊那么。
[9:8.920,9:13.400]  我们当然希望通过这次的这个实验啊，大家对。
[9:13.400,9:14.180]  这个。
[9:14.200,9:15.340]  对一个。
[9:15.340,9:22.300]  Dan c能干多少事情啊，或者我不知道大家用了就是多少的方法去去去解决这个问题啊。
[9:22.300,9:27.280]  而我们给的那个实验平台，其实处理能力也并不并不大，他就是。
[9:27.280,9:31.660]  这三个节点嘛，就是就是，三个cpu，还一个要做管理的吗。
[9:31.660,9:34.600]  那么内存可能每个上面3G啊就是。
[9:34.600,9:38.160]  但是他写了很多的东西啊，分给你的。
[9:38.160,9:44.080]  能用的也是有限的，但是他起码把那如果你是在斯卡拉啊。
[9:44.080,9:44.940]  BOC。
[9:44.940,9:48.800]  而且贝斯而且被死，拿这个做这个可能有点。
[9:48.880,9:52.360]  难一点，我不知道有没有同事尝试拿去背死去。
[9:52.360,9:54.780]  就把它做做出来的那个。
[9:54.780,9:55.900]  就是。
[9:56.300,10:6.620]  就是，反正是他数据的量上和这个计算机处理能力上，那么这里是从这里定义的，其实这里也看出来，为啥人们拿这个来定义啊，他确实是。
[10:6.620,10:10.260]  跟你的这个这个数据，为什么大数据来了跟这个。
[10:10.260,10:11.900]  就是数据量和。
[10:11.900,10:15.480]  处理能力处理方法上不满足是相关的啊。
[10:15.480,10:23.240]  还有一个这个所谓的低密度啊低密度，这也是相对说的，为啥低密度数据量那么大，我们现在的处理能力。
[10:23.240,10:27.180]  有限啊，所以能挖出来的东西有限啊，那么。
[10:27.300,10:28.700]  嗯。
[10:28.720,10:33.640]  如果我们能挖出更多的东西来啊，密度就不低了，但是现状来说。
[10:33.640,10:41.160]  嗯，能挖出来的东西其实还是还是很有限的，换一个角度说，就是还有非常大的空间啊，让大家去。
[10:41.160,10:44.580]  从里面去找到新的方法，找到新的价值啊。
[10:45.220,10:53.460]  那么这个大数据整个这个概念里面还有一些啊，但是应用角度啊，他的分的层次啊这都。
[10:53.460,10:55.400]  我说这个层次实际上。
[10:55.400,10:57.160]  相当多的领域。
[10:57.300,11:4.580]  就是都是这样层次的啊，基础设施数据源，管理层分析，曾当然对大数据他特别就是。
[11:4.640,11:8.860]  嗯，这个分也有一定的特点啊，就是说分析层。
[11:8.860,11:11.340]  什么有平台层、应用层。
[11:11.780,11:13.620]  这是？
[11:13.620,11:15.300]  他的一些橙子方法。
[11:15.300,11:18.540]  那么还有就是这三者之间啊大数据。
[11:18.540,11:20.140]  呃。
[11:20.140,11:21.380]  云计算。
[11:21.380,11:24.140]  物联网啊，就是这三者之间。
[11:24.220,11:27.960]  的关系，其实它确实是这三者之间的这个比较。
[11:27.960,11:28.600]  就。
[11:29.260,11:32.580]  就是有有很多的相关性啊一件事情。
[11:32.580,11:36.600]  嗯，你说是是这个物联网的事。
[11:36.600,11:37.840]  也行是。
[11:37.840,11:46.200]  是大数据的也行，但是我不知道现在大家能不能分清楚我这样说的时候，这件事情到底是从云计算角度看。
[11:46.200,11:48.540]  还是从互联网角度看啊。
[11:48.540,11:49.960]  什么物联网？
[11:50.180,12:6.500]  当然大概这个时候物联网有这个充分的连接进来，他就是感知这个世界的东西嘛，就形成了这样的，这个这个大数据的这样的来源，当然倒过来物联网搞这么多数据进来，他也要大数据的这样的技术。
[12:6.500,12:10.860]  我搞进来才能存才能用啊，就是这样的一种关系。
[12:10.860,12:14.060]  而云计算来说，云计算的。
[12:14.060,12:22.860]  后面还也有专门的章节讲过云计算，核心是把这个东西放在云上，其实我们已经有体验了我们的实验平台。
[12:22.860,12:27.340]  就是这个，就是这样的云，他有一点点延迟啊但是。
[12:27.560,12:30.080]  其他方面来说确实还是。
[12:30.080,12:36.920]  还是很方便的，你像我们这次大数据给大家，哎我在里面，这都是云云里面的技术啦，我打好包了之后。
[12:36.920,12:40.000]  大家在一个账户进去就有这个数据了啊。
[12:40.880,12:47.680]  就这都是这个云计算的，当然云计算里面用的各种技术，他也是想法把。
[12:47.680,12:48.880]  各种的。
[12:48.880,12:52.120]  G就是大数据的处理、数据的技术。
[12:52.120,12:53.560]  在云计算里面。
[12:53.560,12:54.760]  这个用出来。
[12:54.760,13:1.740]  而当然云计算，但是首先核心就是对各种资源的管理，计算资源的这种管理啊这种。
[13:1.740,13:3.680]  分布啊，其实大数据。
[13:4.200,13:15.040]  的技术上，那么把各种计算资源能能用起来，能管理起来，这上面他也很多，其实就是用的和云计算。
[13:15.040,13:16.320]  一样的技术啊。
[13:16.360,13:29.240]  只是比如说有在场景上来说，因为云计算往往一定是在云上比别人提供给你云，提供给你舅舅，大概有这一点差别，你自己管一个实验室，把这些东西用起来，你也要用于类似的。
[13:29.240,13:31.280]  这个云的技术这些。
[13:31.280,13:34.380]  这些节点的加载管理啊，磁盘管理啊。
[13:34.380,13:36.900]  这些也是要用一些类似云的技术的。
[13:37.420,13:43.720]  大概就是这样的几层关系，这些以后在那个应用中也可以。
[13:43.720,13:46.780]  不断的再去体会啊，这三者之间的关系。
[13:47.860,13:49.980]  好，那么就是hadoop啊。
[13:50.100,13:52.540]  Hadoop的话是。
[13:52.820,13:58.100]  大数据就说过啊，说大数据最热的词，最那个啥的应该是啥。
[13:58.120,14:0.920]  就是我记得当时同学。
[14:1.200,14:2.320]  还没。
[14:2.460,14:4.900]  大哈，肚子还是，好像还没有啊。
[14:4.900,14:6.240]  现在应该要。
[14:6.240,14:8.660]  知道啊，就是卡杜甫，确实是。
[14:8.840,14:12.300]  在这个大数据领域是最核心的这样的。
[14:12.580,14:22.240]  其实它是一种思想，它相当于就开启了，因为原来计算机他也这么大的数据，他也不是也有各种方法也想着去处理啊。
[14:22.380,14:25.160]  但是油哈杜普开始。
[14:25.160,14:31.700]  什么事，我找到了一种方法，这个分布式的，这样的一种又比较好操作的。
[14:31.700,14:35.680]  啊又比较能结合起来的一种方法，然后大数据技术。
[14:35.680,14:36.600]  就。
[14:36.600,14:37.860]  不断的发展起来了。
[14:38.280,14:42.880]  那么这张图是相当于这个hadoop的啊，所谓的项目结构。
[14:42.880,14:45.540]  就是现在回头再看一眼啊因为。
[14:45.540,14:47.360]  刚开始一上来看。
[14:47.360,14:50.320]  那么多名词，那么多这个快快，那可能。
[14:50.320,14:51.720]  非常的晕虎啊。
[14:51.780,14:55.100]  我不知道，现在再看一眼是不是能更。
[14:55.100,14:56.840]  能更清楚一点了啊。
[14:56.840,15:2.160]  这个是存储的，这是资源呀，啊资源调度的，当然我们是卖不出deuce。
[15:2.160,15:4.940]  而且base啊这都是仔细讲过的。
[15:4.940,15:8.100]  那么还有这个害物啊害物就是。
[15:8.100,15:12.660]  在上面一层相当于数据分析，其实主要就是。
[15:12.660,15:14.700]  C口的一些支持的啊。
[15:14.700,15:18.960]  C口支持，有不同的努力嘛，还有这个p GE rp格式。
[15:18.960,15:21.460]  不是用C口，但是也是不适用。
[15:21.460,15:22.980]  用一个这个。
[15:22.980,15:23.720]  哎。
[15:23.720,15:28.860]  高级的一点的语言啊来来做啊，包括这个sock shop。
[15:28.860,15:32.160]  是在spa上来支持这个cpu。
[15:32.300,15:36.000]  那么当然核心的啊，计算的机制啊，这个有。
[15:36.000,15:39.480]  有这么mapreduce spark，我们都。
[15:39.480,15:42.040]  都仔细讲过，这是核心的处理机制。
[15:42.040,15:44.860]  还有这样一些词，弗罗姆日志啊，处理。
[15:44.860,15:50.080]  跟还有这个scoop，就是数据要导入啊，这是跟那个。
[15:50.080,15:51.880]  什么数据仓库啊。
[15:51.880,15:54.580]  和这些之间相关怎么把？
[15:54.820,15:59.120]  C口的数据导到这个哈弗体系里面啊，OK，我们。
[15:59.500,16:3.500]  讲的少，他居然教训像人的这个意思啊，怎么样？
[16:3.500,16:7.060]  这个可能还真没咋提过，他其实也是一个。
[16:7.060,16:15.640]  就是所谓的作业留啊，当然他现在放在这，他调度他可以跨不同的这样的平台来调度作业，更那个。
[16:15.640,16:22.120]  你要是简单来看这种作业，留的就是spot，他的那么一个计算过程，太子的一个计算过程。
[16:22.120,16:25.700]  就这么一个惦记图，也可以认为是一个作业留的过程。
[16:25.760,16:29.680]  这这就是我们的程序弄起来，其实你们自己做这个事情。
[16:29.680,16:34.160]  就会，现在我不知道会不会有体会，因为我们这次讲究速度吗？
[16:34.160,16:45.400]  讲求速度的话呢，我不知道你是在CA里面一行的去搞，还是晕一个脚本，这是一块，但还没那么玩呢，你那个数据从解包，你到把它加载到hadoop里面。
[16:45.400,16:47.400]  当然现在我估计啊。
[16:47.400,16:52.400]  你要有二字的话，那可能还能稍微快一点点，现在你起码往这个哈。
[16:52.400,16:55.340]  而且DFS里面加载你只能敲命令了。
[16:55.340,16:57.140]  你要用可能。
[16:57.140,16:59.040]  就是因为没有把那个。
[16:59.220,17:1.340]  岙仔可能还没有用起来啊。
[17:2.240,17:5.580]  这就是他，从体系上来说。
[17:5.600,17:9.840]  但是核心呢，我们还是要知道他是开启了这个大数据。
[17:9.840,17:19.280]  这个处理的这种这种框架，再说到这里面呢，就是关于哈杜普或者大数据的三驾马车啊，也提过几次。
[17:19.280,17:20.260]  这都是。
[17:20.260,17:21.800]  这个跨时代的。
[17:21.800,17:22.940]  呃，就是。
[17:22.940,17:28.000]  相当于大数据引领开始的，我们现在三驾马车，能不能迟到了。
[17:28.640,17:30.440]  说起来，这三驾马车。
[17:30.440,17:33.220]  都跟谷歌相关的，跟谷歌还对应的。
[17:33.220,17:33.940]  这个。
[17:34.000,17:35.200]  删掉吧，撤。
[17:36.760,17:39.940]  他其实就涉及到这个数据的这个。
[17:39.980,17:43.100]  对于这个处理的各个环节嘛啊。
[17:43.280,17:46.960]  这个HDS啊，首先是要分布式。
[17:46.960,17:50.280]  存储文件的存储对应的就是big table。
[17:50.280,17:52.140]  还有分布式处理啊。
[17:52.160,17:53.840]  还有这个。
[17:53.840,17:57.800]  然后还有就是分布式处理，就是map reduce啊。
[17:57.800,18:3.080]  那个还有一个就是这个HBS啊，他那边叫big table啊。
[18:3.080,18:5.000]  嗯，就是。
[18:5.000,18:5.980]  嗯。
[18:6.800,18:8.620]  就是这样的。
[18:8.780,18:15.060]  这三部主要对这个数据处理的几个方向都有咔哇，但是这三部。
[18:15.060,18:18.140]  他都是从谷歌这开创出怎么好？
[18:18.140,18:21.960]  进行分部啊来进行的这样的方式啊。
[18:21.980,18:23.240]  这是？
[18:23.240,18:24.680]  哈，杜埔他的。
[18:25.060,18:26.040]  特点啊。
[18:26.420,18:33.840]  那么这些之后啊，就是计入具体的这个啊，这些部件啊，就是这些技术环节。
[18:33.840,18:35.600]  那么就是HDFS。
[18:36.920,18:40.860]  HDFS是分布式文件存储啊。
[18:40.860,18:42.280]  那么。
[18:42.620,18:43.940]  我们。
[18:44.240,18:47.280]  看一下，实际上就是他可以存储。
[18:47.280,18:48.320]  非常。
[18:48.600,18:50.340]  大量的。
[18:50.520,18:53.200]  文件啊，包括这个文件。
[18:53.200,18:56.860]  嗯，等核心还是这个文件可以非常大啊。
[18:56.860,18:58.040]  那么。
[18:58.760,19:5.260]  嗯，那可能那记啊T啊，甚至一个文件PR都可以，他为什么能存得非常大，因为。
[19:5.260,19:10.360]  他就是一个分布式的框架，它是把这些文件分为了block啊。
[19:10.360,19:16.080]  再来传达，那么block的数目可以非常的多啊，当然你要处理大文件的时候。
[19:16.080,19:18.920]  呃，你你甚至如果你这个系统。
[19:19.600,19:22.900]  处理的都是比较大的文件，你block还可以画大一点。
[19:22.900,19:25.800]  让你的这个管理找block的这个寻址。
[19:25.820,19:29.400]  和会会更简单一点啊这是。
[19:29.400,19:30.780]  他的他就是。
[19:30.780,19:38.400]  实现了我能分布多个block这样一个框架，他为什么能做这个实际上文件分块的啊，我们也说过。
[19:38.700,19:43.160]  就是在现在的文件系统，他也是这么做的，他最后到的那个。
[19:43.160,19:50.480]  他那个叫叫什么散区啊，完了再在网上分，他也是这么分的，他为什么这样能做得好就是。
[19:50.480,19:52.540]  他把这一块搞得很简单啊。
[19:52.580,19:56.400]  那么但是呢，就把最核心的问题就能解决了。
[19:56.700,20:3.920]  这个HDFS，它能支持大数据，除了就是他这么能用block分部的方式。
[20:3.920,20:4.760]  能。
[20:4.760,20:5.580]  纯。
[20:5.580,20:8.800]  对应很大的文件之外啊，那么他还解决了。
[20:8.940,20:19.720]  从另一个角度，它是可以支持廉价的硬件啊，他就是对存储的，对计算机的这个要求不这么高，或者是说他是用他的这个备份的方式啊。
[20:19.760,20:21.000]  那么。
[20:21.000,20:23.080]  一般是默认三个备份吗？
[20:23.080,20:25.000]  用三个备份的方式。
[20:25.100,20:29.360]  使得因为因为本身硬件出这个的几率啊。
[20:29.360,20:31.920]  还是比较低的啊虽然是。
[20:32.220,20:34.660]  廉价的硬件会高一些，但是。
[20:34.660,20:39.980]  相对比较低，那么两个备份，就是他比万分之一两个备份，就是百万分之一。
[20:39.980,20:46.720]  他应该比万分之一还的啊，因为他处理的这个数据量非常大，三个备份那就是。
[20:47.360,20:49.780]  咱们多就就又多少多少分之一。
[20:49.780,20:51.540]  那么这样的这个。
[20:51.540,20:57.440]  呃问题举例使得它的硬件儿，而且它里面这些机制可能都相对是。
[20:57.580,21:0.180]  是可以自动的啊，哪里出了问题。
[21:0.180,21:4.020]  他就哪个block出了问题，他再复制一份出来。
[21:4.020,21:8.680]  就可以继续来来应用了啊，这是他的这个。
[21:8.700,21:12.280]  这个特点当然它本身也是。
[21:12.480,21:13.660]  这个。
[21:13.880,21:15.000]  就是。
[21:15.080,21:16.240]  呃。
[21:16.240,21:18.840]  体现了啊，就是。
[21:18.840,21:20.180]  嗯。
[21:20.180,21:28.860]  这种分布式管理的啊，这个或者框架或者这种结构模型啊，它它的这个结构模型实际上。
[21:28.860,21:33.700]  是也就是哈杜普最核心的这种模型啊，就这种主从模型。
[21:33.700,21:36.580]  有这个mast有slave嘛，当然不同的。
[21:36.580,21:39.060]  其实我们看到后面的各种的。
[21:39.060,21:45.280]  呃，实现方案在这个结构模型上都是类似这样的方式的啊，只不过。
[21:45.280,21:48.760]  呃每个方案上他可能就是具体。
[21:48.760,22:0.560]  这些模型的这个部件叫什么啊什么的，会会不一样啊，他的工作的过程也会不一样，因为还是有侧重的，但是它和新的想法还是一个中心的管理，然后。
[22:0.560,22:4.220]  把工作分给各个节点，这是一个。
[22:4.300,22:10.140]  在这个层面上的一个扁平的结构，那么我各个节点都是对等的，那对等的。
[22:10.140,22:13.040]  平等的，那么这些节点越来越多。
[22:13.040,22:15.900]  就可以这么水，这就水平扩展了。
[22:15.900,22:22.100]  那么在这个里面对他来说，就是就是叫名称节点和这个。
[22:22.100,22:23.140]  呃。
[22:23.140,22:27.220]  数据节点啊，就是那个带他node name node啊。
[22:28.100,22:32.180]  那么他也是用这样的结构啊，那么就使得。
[22:32.180,22:33.480]  他的就是。
[22:33.480,22:35.440]  支持这个大数据存储。
[22:35.620,22:38.160]  嗯，这个成为可能，这也是。
[22:38.180,22:40.860]  这个哈佛的基础，这也是。
[22:40.860,22:45.800]  这个分布式的这个机制的基础，这也是大数据处理的。
[22:45.800,22:47.340]  这种开端啊。
[22:47.760,22:52.580]  呃，当然它的访问啊，还有一些我们也涉及到，你是可以。
[22:52.580,22:54.620]  拿这个Java的这一些。
[22:54.620,22:57.780]  这些API来来来访问的啊，这是？
[22:58.640,22:59.920]  嗯。
[23:2.980,23:5.520]  这就是这个。
[23:6.000,23:8.120]  HDFS啊，那么。
[23:8.120,23:9.340]  这是他的。
[23:9.340,23:10.200]  核心的基础。
[23:10.840,23:19.220]  嗯，我们当时讲，后来是接待TFS，我们因为想把那个哈杜普的这个，呃核心的啊基础讲下来我们。
[23:19.820,23:25.620]  呃，讲的时候是从这就跳到这个map reduce去了啊，有文件存储了，那么就是。
[23:25.620,23:28.440]  那么就有对这个数据的核心处理机制啊。
[23:28.440,23:31.280]  这里我们顺着这个书上的章节来说啊。
[23:31.280,23:34.540]  现在我不这样打，我大家应该不会。
[23:34.540,23:39.780]  很小，因为而且base就是它相当于还要提供这个数据库的能力。
[23:39.780,23:44.520]  因为真正处理数据，把数据放在文件里面。
[23:44.520,23:45.600]  还是。
[23:45.600,23:49.980]  有限制的啊，那么我们就要把它放到这个。
[23:50.780,23:51.920]  嗯。
[23:52.260,23:54.780]  就呃，把它放到那。
[23:54.780,24:2.780]  就是要一定的用一定的数据库技术啊，把这些数据更好地组成组织起来，那么而且背死呢。
[24:2.780,24:3.680]  所以。
[24:4.160,24:9.720]  你的一个一个数据处理系统啊，就没有这一块肯定是不。
[24:10.100,24:12.280]  不完善的或者是不好用的啊。
[24:12.280,24:16.420]  所以为，他说这刚才说的三驾马车啊，就是文件能存住了。
[24:16.420,24:19.240]  由mapreduce他能处理了其实。
[24:19.240,24:22.420]  你索索有的是，你拿奶粉就死。
[24:22.560,24:26.680]  去干也完全不是说完全不能干啊，但是。
[24:26.700,24:30.060]  还是会很会很费劲啊，所以要有一个。
[24:30.060,24:31.500]  这个历史。
[24:31.500,24:37.880]  数据库的东西，实际上这就当C口了，因为后面还有专门讲那个no c口的这一部分。
[24:37.880,24:39.580]  在这里，其实也已经。
[24:39.580,24:43.740]  引进了啊，这个一定的这个no sequel的这个。
[24:43.760,24:47.120]  这个概念啊，那个。
[24:48.320,24:52.500]  那么对于h base来说呢，实际上。
[24:52.500,24:53.880]  他是。
[24:53.920,24:58.520]  他也是在那种分布式的框架上啊，那么来实现。
[24:58.520,25:0.040]  嗯，纯。
[25:0.040,25:1.640]  多个这个。
[25:1.640,25:2.380]  就是。
[25:2.380,25:7.640]  呃，陈非常大的数据量的啊这样的一个数据库。
[25:7.640,25:10.720]  那么其实它实现的思路基础上的思路。
[25:10.720,25:13.080]  也类似啊，你HDFS。
[25:13.080,25:19.140]  嗯，为啥能存的大，他就是把，当然他是把block那块这件华啊来。
[25:19.140,25:22.200]  来来做就是相当于文件分块。
[25:22.200,25:24.180]  这块儿来简化来做。
[25:24.180,25:27.460]  而这个H背死呢，它相当于是。
[25:27.460,25:29.360]  相当于是在那个基础上。
[25:29.360,25:36.200]  因为数据放在文件里和放在数据库里，其实最大的一个差别就是。
[25:36.200,25:37.920]  就是你的数据。
[25:37.920,25:42.200]  是不是可以比较方便快速查找，这其实就索引了啊。
[25:42.200,25:45.700]  那么就是有一定的这个索引方式。
[25:45.700,25:52.480]  按照一定的规律啊，把它数据放到文件里面去，这个是数据库做的。
[25:52.480,26:2.020]  但是这不发展的很那个，其实传统的这个关系型数据库，在这一块弄得已经非常那个，他为了把数据组织起来，有各种各样的方式，但是。
[26:2.020,26:4.820]  那快走到了，这个方式太复杂了。
[26:4.820,26:8.300]  那么使得它的这个分部呀什么。
[26:8.660,26:9.660]  不可以做。
[26:9.680,26:14.860]  不好做啊，那但是h base在这倒过来啊，我核心就是把这个数据。
[26:14.860,26:16.680]  我按照一个最。
[26:16.820,26:18.060]  相对。
[26:18.100,26:21.400]  简单的原则，我把它组织起来。
[26:21.580,26:22.700]  那么。
[26:23.380,26:27.400]  这样的话我就可以纯这个一个很大的这个。
[26:27.400,26:29.040]  呃这个数据啊。
[26:29.040,26:32.800]  那么它实际上存的这个方式啊我们。
[26:32.800,26:36.560]  对于我们也做过一些这方面的编程啊，做过。
[26:36.560,26:44.020]  应该这块会理解的稍微深一点啊，他是拿这个行啊，其实就行见。
[26:44.020,26:48.040]  相当于他是拿航舰把这些数据拍起来的。
[26:48.040,26:53.460]  当然他数据，因为还有各种各种种类啊，所以呢，它又搞了一个列族。
[26:53.460,26:55.720]  这样的方式啊就是。
[26:55.720,27:2.180]  拿行建来排序，但是拿猎逐来划分这个大的这个数据块。
[27:2.180,27:6.060]  嗯，裂组里面的还有这个，还有列啊这个。
[27:6.380,27:8.580]  用这个列组里面的列。
[27:8.580,27:9.380]  Life。
[27:9.580,27:13.960]  区别就是每个就数据这样的这个多样性啊。
[27:13.960,27:16.200]  那么它在整个的这个。
[27:16.660,27:17.780]  嗯。
[27:17.780,27:28.320]  呃就是为了分布式啊，为了这个包括速度啊，就是在这方面的管理，他还做了一个特性，就是其实它数据是不能。
[27:28.320,27:29.880]  不能去改的啊。
[27:29.880,27:34.640]  他不能改，但是他怎么支持这个数据的变化，就是用这个时间戳。
[27:34.640,27:35.960]  相当于。
[27:35.960,27:40.040]  用时间拖，而且他给每个数据之上都带上时间拖。
[27:40.040,27:43.720]  修改数据就变成了你家一个新的时间，错。
[27:43.720,27:55.200]  上来当然我们甚至是成了，我们有时候直接拿时间搓来用啊，你这个数据有很多的值，我都想用，我就拿时间搓，把它分开，也可以传承多个数据。
[27:55.200,27:59.740]  多少分，我们好像有的，十堰里就有点类似这样的。
[27:59.740,28:0.820]  这样的做法。
[28:0.820,28:2.160]  这也是可以的啊。
[28:2.160,28:4.760]  当然最后我确定这么一个。
[28:4.760,28:8.060]  他这个feel单元的方式就是要。
[28:8.060,28:9.280]  行，建。
[28:9.280,28:10.440]  猎足。
[28:10.540,28:12.440]  呃，列。
[28:12.440,28:15.060]  在家时间搓，这个时候我可以确定。
[28:15.060,28:16.000]  一个。
[28:16.160,28:17.500]  具体的一个值。
[28:17.700,28:23.100]  这是在，但是这个其实还是就比较简单，就是这么一个数据收银过程。
[28:23.100,28:27.300]  但是他在整个支持大数据的这个情况下，因为。
[28:27.300,28:34.560]  这个所谓的大数据，我就是这个里面有非常多的行，但他也分另外一个大的地方啊，我也可以这个烈非常差啊。
[28:34.560,28:36.660]  这个是对他来说。
[28:36.660,28:41.500]  嗯，也是坐着，他为啥有猎足啊和这样的方法，这是列。
[28:41.500,28:44.860]  这是另外一种考虑啊，我这个列可以非常的长。
[28:44.860,28:49.900]  而且我的列的行李里面存的内容的格式，其实。
[28:49.900,28:53.220]  就相对比较自如，这是他另一个方面的考虑。
[28:53.220,28:56.100]  而对于航非常多的这一部分。
[28:56.680,28:58.840]  他就是用risen来管的啊。
[28:58.840,29:1.080]  Region实际上就是把行。
[29:1.080,29:6.580]  分段啊，就是这样的话，就分成分成一块一块的，那么一个raging，一个ready。
[29:6.580,29:13.600]  那么这些raging就把它分不起来，这个raging分不出来，和那个block分不出来，分不开来的。
[29:13.600,29:16.020]  这个方式和这个其实。
[29:16.020,29:17.200]  就是很像啊。
[29:17.200,29:23.240]  当然它里面又因为它这个里面就是索引的block的那个。
[29:23.380,29:25.700]  的这个分布方式的话。
[29:25.800,29:33.940]  它的缺点就是我的一个一个大block，所以对用户来说，实际上它基本上你看不到的，它因为它纯的时候。
[29:33.960,29:35.180]  这个。
[29:35.740,29:42.780]  嗯，我只知道传到这个文件里了，那么我到这个文件里面要去找他实际上。
[29:42.780,29:45.520]  你你图文见你是没没法这么做的。
[29:45.520,29:47.540]  你要文件里面去找一个东西。
[29:47.540,29:51.120]  你只能对用户来说，你只能把这个文件。
[29:51.120,29:52.760]  读出来就顺着看吧。
[29:52.760,29:55.560]  看看啊，我找到了这个文件里的这个东西。
[29:55.560,30:4.900]  这个就是纯文件，但是纯这个就不一样了，纯这个呃，H base存到数据库里就不一样了，我要找哪条记录。
[30:4.940,30:7.380]  这是可以的，这样的话。
[30:7.560,30:9.560]  当然，所以它的region。
[30:9.560,30:23.200]  和block也是有差别的，它reading是按照航航建来划分的啊，当然这个raging行建怎么画啊，就是说还有一些有些方法，但是还要考虑到他的这个存储的分布的均匀性。
[30:23.200,30:30.760]  访问的这个这个均线这些都有一些的方法，但是他是要reading和航间之间。
[30:30.980,30:32.280]  还有一套。
[30:32.280,30:42.260]  一套这个对应关系，那实际上就是一个这个分配表儿，这个分配表他又有一套机制，因为因为这个分配后呢，他发现一级索引是不够的啊。
[30:42.260,30:45.020]  就是因为这个。
[30:45.020,30:50.040]  呃，他纯这个raging荷航舰对应的话。
[30:50.040,30:55.580]  就这个关系，如果对于非常大量的一个数据的话，它是不行的，所以他又有两层的这个。
[30:55.680,30:56.600]  就是。
[30:56.600,31:0.020]  这个对应关系啊，那么就。
[31:0.020,31:5.000]  可以来实现非常大量的这种这种存储。
[31:5.140,31:7.960]  那么他的构架上面啊就是。
[31:7.960,31:16.580]  使你看master slave之就是must主服务器和这个region服务器啊，这是它的核心的这个框架啊。
[31:16.580,31:23.200]  当然它还涉及到一些什么，猪keep啦，这些的话，我们可以在后面还会还会提到这个事情。
[31:23.200,31:24.900]  那核心来说啊。
[31:24.900,31:26.660]  就是h base。
[31:26.820,31:31.340]  从hadoop的这种分布式的框架基础上。
[31:31.340,31:32.960]  把这个。
[31:32.960,31:41.180]  文件相当于就是把这个数据库，相当于就是能索引的，这样的数据啊，去存储起来。
[31:41.180,31:43.400]  其实提供了这样的一套机制啊。
[31:43.440,31:45.520]  这是这个。
[31:45.720,31:49.520]  而且被子啊这个做到的事情。
[31:50.520,31:53.660]  啊那么到回来就是。
[31:53.660,31:55.080]  相当于补了一次。
[31:55.080,31:59.700]  一些就是在从一定从理论上啊，来看一下这个。
[31:59.700,32:4.320]  前面这个做的过程就讲这个no c口啊，那么OC口是啥意思。
[32:5.740,32:9.600]  是notes equal还是note only c口啊这个人。
[32:9.600,32:13.760]  也说过这有一个人们发展认识的，这样的一个过程啊。
[32:14.360,32:21.000]  嗯，那么，当然现在我们认识no c就是note only c口啊，就是。
[32:21.000,32:22.200]  不能只只。
[32:22.200,32:24.380]  仅仅是C口语言啊。
[32:24.380,32:25.340]  当然。
[32:25.380,32:33.060]  当然这里包括你对C口语言可能也得有还是有什么，它是一个关系话查询的这么语言啊，那么。
[32:33.060,32:36.580]  它是由她的这个数学基础的，然后。
[32:36.580,32:46.340]  它可以保证你各种各样的关系啊，各种的方式都能都能被查询到，那么有这样的语言，他为什么能发展出有这样的语言确实应用。
[32:46.340,32:51.560]  就会很很方便啊，我们后面会看到，虽然讲apt但是。
[32:51.780,32:57.300]  很多的系统，它到最后还是想法提供出这个C口接口来啊。
[32:57.620,33:2.300]  但是在这里还是先得看这个no c CA本身的这个。
[33:2.300,33:3.460]  发展的。
[33:3.480,33:4.980]  程度那么。
[33:5.100,33:8.240]  他相当于他先解决。
[33:8.240,33:13.920]  我把这个查询接口简化下来的情况下，我先解决这个大数据的问题。
[33:13.920,33:15.880]  而且一定程度上他还。
[33:15.880,33:19.580]  有理论基础的，所以它的理论基础就是这个。
[33:19.640,33:21.500]  什么cup理论啊？
[33:21.520,33:23.940]  太不理论的话就是。
[33:23.940,33:25.020]  嗯。
[33:25.420,33:26.660]  嗯，就是。
[33:26.660,33:29.680]  就是可用性啊这个。
[33:29.680,33:34.160]  呃一致性，分布性啊，就这三个东西是不可。
[33:34.160,33:40.760]  同时兼得的啊，这还是一个很重要的基础，它其实我们还举过一个例子啊为什么。
[33:40.760,33:43.080]  这三者不可监督啊，因为。
[33:43.080,33:46.300]  就是这里说的这个分布性，就是知识大数据。
[33:46.300,33:52.220]  的话，那么你的东西就是要分成很多区的，因为我们看到这个大数据。
[33:52.220,33:54.840]  核心的这个知识方法就是靠这个。
[33:54.840,34:0.020]  塔提审啊，就是把它分成很多的区块来弄的啊，那么。
[34:0.020,34:1.780]  嗯，这个。
[34:1.780,34:7.700]  但是可用性呢，就是说始终这些数据都是都是可用的啊，你的系统。
[34:7.700,34:8.540]  嗯。
[34:8.560,34:9.460]  的。
[34:9.460,34:12.200]  整个系统始终都可以提供。
[34:12.200,34:14.580]  这个可靠的服务。
[34:14.580,34:17.180]  呃，可用的这种结果啊。
[34:17.180,34:18.480]  那么。
[34:19.020,34:20.140]  这个。
[34:20.140,34:23.460]  嗯，一致性呢，还是就是说他们。
[34:23.460,34:26.280]  你在这不同的地方访问出来的东西。
[34:26.280,34:28.340]  不能不一样啊，就是。
[34:28.360,34:37.840]  大概就是这几种的东西放在一起，所以就有各种组合啊，C组合，CP组合啊，什么APP组合。
[34:37.840,34:40.280]  就是倾向于这些的时候。
[34:40.280,34:42.660]  那么是哪一种技术因为？
[34:42.660,34:47.000]  那个理论那个证明其实并不是很复杂啊，就讲了这么一个场景，就是说。
[34:47.000,34:49.440]  你你就是不可做到的，所以。
[34:49.440,34:54.560]  嗯，你做到这些的时候，你都得容忍一些就是其他的这个缺陷。
[34:54.560,34:59.820]  那么各种你像呃C可能就是传统的这个数据库。
[34:59.820,35:2.760]  更多的就是这个这个C的啊。
[35:2.760,35:4.500]  那么这个。
[35:4.500,35:9.580]  呃，带P的就是这个大数据，弄得这些就是就很多是带P的啊。
[35:9.580,35:10.460]  那么。
[35:10.460,35:13.400]  而且他会考虑这个IP的。
[35:13.400,35:16.140]  又一波考虑，CP的又是一波。
[35:16.180,35:21.600]  那么这是他的一个理论，那么还有一步一个理论，就是这个代词啊这个。
[35:21.600,35:25.020]  什么基本可用，最终一致一致性啊。
[35:25.020,35:30.820]  就是就这几个理论的，他对的是大概是什么。
[35:30.820,35:34.100]  什么意思啊，那么你要理解啊。
[35:34.940,35:42.860]  嗯，在这张里面还讲到了一个这个文档数据库啊，文档数据库，实际上它它里面存的那个结构啊，就是这个哒。
[35:42.860,35:45.820]  Document的啊，就是一相当于把一篇。
[35:45.820,35:51.560]  这个n n documents的，这样的结构来存这个数据库啊它。
[35:51.560,35:54.980]  也是这个囊C口中的一种啊那。
[35:57.020,36:0.320]  这个是no c口啊。
[36:0.580,36:5.060]  那么还有就是第六章就是这个。
[36:5.140,36:8.480]  嗯，云数据库啊那个。
[36:13.140,36:14.400]  云数据库。
[36:15.860,36:20.680]  嗯，实际上这里就是他介绍了很多，就是这个。
[36:20.720,36:22.420]  云的这个。
[36:22.420,36:23.840]  云的概念啊。
[36:23.840,36:25.080]  那么。
[36:25.080,36:29.700]  在云数据库的这个这个上面啊，把这个云的。
[36:29.700,36:33.320]  概念来来提出来这个介绍了，那么。
[36:33.320,36:41.980]  呃包括云上面的这个各种玩家啊，那么云能，能带来的这种这种好处啊。
[36:41.980,36:43.140]  那么。
[36:43.140,36:51.060]  嗯，当然，实际上这个云上面提供的先是这个计算平台啊，就是我们所看到的这个这个数据节点。
[36:51.060,36:53.380]  那么在这个计算平台上。
[36:53.380,36:54.520]  嗯，这。
[36:55.140,36:56.180]  就是。
[36:56.180,37:3.440]  其实就是一个最盛，就是一个计算资源了啊，他你你可以拿到这个cpu拿到。
[37:3.440,37:5.100]  拿到内存，拿到存储。
[37:5.100,37:8.000]  这是一个个的这个节点，但是。
[37:8.000,37:9.340]  云的提供。
[37:9.500,37:12.780]  台湾忘叫，而且提供这些节点的。
[37:13.680,37:18.200]  相当于他这个服务啊，提供的就少一些嘛，竞争也很激烈，这一部分。
[37:18.200,37:24.220]  现在就非常便宜，完了，大家都在努力在上面去增加多的多的东西啊。
[37:24.220,37:32.600]  那么上再往上一层就是计算节点啊，那么这里它其实又给了你一个计算框架啊，就比如给了你这个map reduce。
[37:32.600,37:34.780]  那么或者给了你可能。
[37:34.780,37:39.500]  Spot了，或者给了你一个应用服务器啊，就是这些。
[37:39.500,37:43.780]  是另一层，那么在网上的一层又搞了那个。
[37:44.080,37:46.460]  就数据库啊，我能计算了。
[37:46.460,37:49.440]  嗯，我当然还要有这个数据，当然。
[37:49.440,37:55.280]  提供基本的节点里面嗯，啊对，包括如果我提供一个分布式的存储啊。
[37:55.280,37:57.660]  那么也是只也是。
[37:57.660,38:9.380]  就是数据存储也是可以在云上来提供，而现在大家的做法就是而且在网上，就是在这个云这里面有有整个的什么三层这个服务啊，就是这个什么。
[38:9.380,38:12.980]  R r is啊，这个。
[38:12.980,38:15.680]  啊，就是。
[38:15.840,38:19.940]  就是这个音，就是相当于这个。
[38:19.940,38:20.900]  嗯。
[38:21.040,38:27.300]  Instruction啊呃service那个完了平台service还有这个服务。
[38:27.300,38:29.360]  S啊，就是。
[38:29.480,38:31.080]  或是英文service。
[38:31.080,38:38.940]  那么通过不同层面的这个提供，那么大家都可以在上面来共享这个平台。
[38:38.940,38:40.680]  而且这个云平台。
[38:40.680,38:42.040]  或者云。
[38:42.040,38:44.580]  他从这个应用上是。
[38:44.580,38:47.920]  有一个，另外这个很重要的一点就是。
[38:47.920,38:50.700]  就相当于是把资源的利用率能提上去。
[38:50.700,38:53.400]  这样的这个这个的前提的雨。
[38:53.400,38:57.000]  的原因就是实际上各种应用啊。
[38:57.000,39:6.300]  相当多的这种这种应用它是不饱满的啊，这这其实这也是跟那个，就像如果跟交通类笔试的还是有一波路。
[39:6.300,39:7.320]  他是。
[39:7.960,39:16.020]  嗯，就是即使很拥堵的城市，它也有一些道路是没人走的，这是或者走的人相对少的，当然。
[39:16.020,39:17.720]  这是因为人们。
[39:17.720,39:20.600]  这个不知道，或者是。
[39:20.600,39:22.640]  就是反正各种原因吧这个。
[39:22.640,39:30.220]  数他，他就是这样的一个分布规律，而云使得大家把这些空闲的资源可以。
[39:30.220,39:33.040]  互相的调度共用起来，那么。
[39:33.040,39:40.060]  那么这样的话，整个的这个硬件利用率啊，整个的成本还是可以可以下来一节子啊。
[39:40.060,39:41.860]  这都是云。
[39:41.860,39:43.900]  所带来的好处，当然。
[39:43.900,39:49.060]  你是不是上云啊，那么你作为如果作为一个。
[39:49.060,39:50.420]  一个。
[39:50.460,39:54.880]  对，因为最后上不上云，实际上是一个一个经济问题啊。
[39:54.880,39:59.980]  那么是一个经营实体啊，需要需要决策的这样的一个问题。
[39:59.980,40:2.540]  你到底是自己搞还是在？
[40:2.540,40:5.700]  在云上啊，那么因为在云上的话。
[40:6.460,40:9.740]  会有一些还是有一些这个担忧的就是。
[40:9.740,40:10.820]  东西毕竟。
[40:10.840,40:13.580]  不归你管，你的依赖于这个云。
[40:13.580,40:15.960]  供应商，他确实能保证。
[40:15.960,40:17.120]  这些安全性。
[40:17.120,40:19.040]  但往往来说可能。
[40:19.040,40:22.540]  会比你自己保证并不并不差啊。
[40:22.540,40:27.060]  当然当然，云因为它有互相的干扰，他比你更难一点，但是。
[40:27.180,40:32.240]  比你自己建一套更难一点，但是它更专业啊，它有各种各样的工具。
[40:32.240,40:38.140]  所以这两者确实是一个权衡一般，当然大企业他实力很充足，就还会自己搞。
[40:38.140,40:40.940]  那么小黑现在可以。
[40:41.080,40:42.880]  可以选择上云啊。
[40:43.860,40:47.380]  这是关于这个。
[40:47.880,40:49.160]  云计算啊。
[40:50.380,41:6.020]  那么这些弄完了，他就进入到这个，啊就是比较核心的，因为我们讲分布式存储啊，这是一个这个大数据的这个这个基础部分，那么你把文件这些能光能这个存储起来。
[41:6.020,41:7.420]  肯定还是。
[41:7.420,41:9.400]  还是不行的啊，那么。
[41:9.400,41:12.320]  所以呢，就是要能去计算。
[41:12.320,41:15.540]  车能就是能分布式的去处理啊。
[41:15.540,41:22.860]  分布式的处理其实比分布式的存储可能更麻烦一点啊，因为存储上其实还是很。
[41:22.860,41:27.720]  一定说还好理解吗？我就是把它分成骗了，一片一片的。
[41:27.720,41:28.860]  那么分。
[41:28.860,41:31.060]  多少多少个那个。
[41:31.060,41:39.320]  呃，相同的骗我都可以，但是纯计算处理就不一样啦，因为这些数据你也不知道哪些和哪些有关系。
[41:39.320,41:44.840]  所以呢，这个计算的这个处理过程中，你就得把这些。
[41:44.840,41:48.560]  所有分片的，或者你所有的看到的这个大数据及。
[41:48.820,41:52.980]  之间的这些关系，你要能进行处理，能进行变换。
[41:52.980,41:55.700]  那么这样子的话。
[41:55.700,42:3.120]  就会就就带来的这个挑战还是非常大的啊，因为因为这里就还是说到过就是。
[42:3.120,42:6.880]  这个计算机我们现在用的这个计算架构啊。
[42:7.420,42:8.860]  那个什么。
[42:8.860,42:13.280]  汾什么诺，1万这样的架构核心到最终还是。
[42:13.280,42:20.480]  一个一个一个现行处理的架构，你要把你的数据和处理逻辑，在通过cpu。
[42:20.480,42:22.640]  在他的这个电路执行过程。
[42:22.640,42:23.720]  是这样。
[42:23.720,42:26.960]  这样子的，线性的这么一条过来的。
[42:26.960,42:32.660]  那么反正最终的话，你的这些处要处理这些数据，要进入到内存里面去。
[42:32.660,42:35.820]  那么进入到内存里面去的话。
[42:36.280,42:37.680]  那个。
[42:37.680,42:39.120]  嗯。
[42:39.120,42:44.960]  但是肯定是内存是放不下的啊，我们之前碰到的问题就是还是单机。
[42:44.960,42:53.160]  你单机的话，你你你你单机内存再大，我们家现在的企业用的也挺大的，像我们看到的那个。
[42:53.160,42:59.560]  都有几百兆的这个，呃几百个G的这个内存，就我们这个实验平台，我们这个实验平台是拿。
[42:59.560,43:1.680]  是拿一个比较大的这种。
[43:1.820,43:5.160]  这种所谓企业企业用的这种机器啊。
[43:5.160,43:8.440]  他还是有几百兆的内存，好像有。
[43:8.440,43:13.000]  有60多盒的这个30多还是60多核的cpu嗯。
[43:13.480,43:14.660]  但是。
[43:14.660,43:17.980]  比起这个大数据来说，这个内存。
[43:18.620,43:20.140]  肯定不够用的。
[43:20.140,43:26.320]  那么这个时候你要想处理他的时候，因为你不知道哪一部分数据和哪部分数据有关系。
[43:26.380,43:33.900]  你说我存储没问题，我就分辨存储了。当然有的时候存储因为也过cpu，你肯定要把它拍拍。
[43:33.900,43:39.820]  就是稍微变化一些，整理一些结构啊，但是没关系，我整理了一块，我就放一块儿放一块儿。
[43:39.820,43:42.140]  我放很多block是没有问题的。
[43:42.140,43:44.620]  但是处理的时候就不行了。
[43:44.620,43:51.740]  处理的时候，因为我整个啊一个P的数据，或者这么大量一个数据，你也不知道哪个跟哪个有关系。
[43:51.740,43:54.360]  我是可以在内存里面调。
[43:54.360,43:55.800]  只调进来一部分。
[43:56.080,43:58.740]  呃，然后轮着掉但是。
[43:58.740,44:0.120]  调进来。
[44:0.120,44:1.420]  把哪些？
[44:1.560,44:4.260]  留在内存里把哪些？
[44:4.280,44:9.640]  去那个就轮换出去啊，这个是很难选择的。
[44:9.640,44:11.320]  那么或者。
[44:11.320,44:15.420]  你没有一个好的框架就没法这么去做的啊。
[44:15.420,44:20.040]  那么所以就是这种这么大大数据量的这个处理以前。
[44:20.040,44:25.800]  是没有好办法的，所以只能去边特定的这个程序啊，特定的东西去弄啊。
[44:25.800,44:31.260]  而map reduce啊就是提供了这样的一个框架，它实际上也就是两次变换。
[44:31.260,44:33.280]  他的这两次变换。
[44:33.280,44:35.600]  就是或者是什么。
[44:35.820,44:37.940]  或者这三次变换。
[44:37.960,44:42.980]  他这三次变换，使得你这个所有数据量之间的关系啊。
[44:42.980,44:45.040]  啊，你可以这个交互。
[44:45.040,44:46.440]  呃进行一次。
[44:46.480,44:52.240]  所以对这个麦克，就是它核心的过程中，我们说过他这个核心是他的那个沙发。
[44:52.240,44:53.680]  就是他那个洗牌过程。
[44:53.680,44:55.560]  他的洗牌过程。
[44:55.560,44:59.160]  就是让所有的数据啊，有。
[44:59.440,45:6.200]  有就是有一定程度再相遇，这样我们像我们也看过例子啊就是。
[45:6.200,45:10.100]  他做这个word cons啊，他包括他可以做排序啊。
[45:10.100,45:15.920]  这个他都是说你看我先哪一哪一层，先按照这个关系。
[45:15.920,45:20.600]  因为有一种关系建立出来的时候，我就可以有这种关系的分段。
[45:20.600,45:22.800]  那么但是呢。
[45:22.800,45:26.620]  那种关系呢，它又有另外一种那种关系的分段。
[45:26.620,45:35.380]  那么你不能限制这样的分段能力，而map reduce他给你提供了一个啊，当然他就这两步，就是这两种关系。
[45:35.380,45:36.500]  交叉一下。
[45:36.500,45:37.660]  这样的一个机制。
[45:37.660,45:40.900]  这个和这个核心机制就是在他的这个沙发。
[45:40.900,45:50.960]  里面来实现的，我们做过的康德的做法也就是，啊我先，我因为先进行这个处理的时候，我在这里是按照你的这个。
[45:50.960,45:52.840]  这个词来。
[45:53.220,45:54.480]  反正来累。
[45:54.480,46:0.440]  不管就是或者是我按照你你各种文件里，其实都是乱的，各种词都是乱的，但是我。
[46:0.440,46:4.880]  每一小段每一小段的此来累，但是我在往下发的时候。
[46:4.880,46:10.580]  这我这些词就得按照我的reduce的那个分段来。
[46:10.580,46:15.800]  重新分好段啊，但是这个过程洗牌过程还是很复杂你的。
[46:15.800,46:19.620]  你如果两边啊，就是相当于是两。
[46:19.620,46:23.720]  整个集群都要交互一下的时候，你就是得有一个。
[46:23.720,46:24.640]  非常。
[46:24.780,46:32.880]  非常大的一个分段过程，对对词来，对词频统计来说，当然前面的话，我为什么要多个APP。
[46:33.260,46:42.520]  那么多个web是因为我可能是统计一个大文件啊，当然，当然这里你看它跟那个S是结合起来，我统计一个大文件。
[46:42.520,46:48.760]  我一个PB的文件，在HDFS里面，我自然的已经分成block了。
[46:48.940,46:53.540]  那么这个时候我就可以让这个迈普任务。
[46:53.540,46:56.640]  在每个block上并行的进展进行。
[46:56.760,47:1.640]  那并行的进行出来之后，我每个脉搏任务都得把它。
[47:1.640,47:2.820]  分出。
[47:3.320,47:9.400]  到我最后reduce reduce就不是按这个文件，这种天然分段来了，就得按照瓷瓶的。
[47:9.400,47:12.940]  比如词打头的，这个你看着60分多少。
[47:12.940,47:14.780]  我reduce如果。
[47:14.780,47:25.260]  呃，这个你当然量少，我们做的实验上可能reduce就一个两个，所以你分一个这个，哎到什么。
[47:25.580,47:28.480]  凯伦的N啊，完了什么o到S。
[47:28.480,47:34.840]  就分这两段就行了，但是如果量非常大的话，就是用你可以分很多，你就是AI打头的。
[47:34.840,47:38.820]  完了，什么AB打头的，这样的，你可能可以分几百个reduce。
[47:39.260,47:44.920]  那么当然你每一个迈普都得分出这几百个reduce，然后是这么一个大交叉过来。
[47:44.920,47:49.480]  但是这样的他就是给了你一个，大家互相相关的东西。
[47:49.480,47:52.000]  都能遇到的这么一个一个机制。
[47:52.300,48:0.080]  呃，有那这样的一个过程的话，那么你一个PPT的那或者是甚至CB的词频统计。
[48:0.080,48:2.140]  你都可以，而且你可以调动。
[48:2.140,48:4.320]  几百个这个。
[48:4.320,48:6.180]  Cpu啊几就是。
[48:6.180,48:14.060]  几百个节点啊，而且他这种做法是你这些节点上，你的一个卖，卖produce的一个进程在。
[48:14.060,48:18.080]  你在一个机器上，不在一个机器上，他都是他，都是可以处理的。
[48:18.120,48:20.820]  所以他就有了这样的一个框架。
[48:20.820,48:22.040]  使得。
[48:22.040,48:23.280]  我们可以。
[48:23.280,48:26.160]  对，非常大的这个数据量。
[48:26.160,48:27.480]  来进行处理啊。
[48:27.480,48:30.960]  那么当然他的用起来啊还。
[48:30.960,48:32.520]  我们边的那个。
[48:32.520,48:33.940]  程序我。
[48:33.960,48:37.780]  不是，就是你最核心的那一个单元处理和那个。
[48:37.860,48:45.340]  的东西，那个算法对你自己编的。其实你要对这个两个变换过程中的时之钥有清楚的理解。
[48:45.340,48:47.640]  你才能把它把它写出来。
[48:47.640,48:50.680]  就是但是mapreduce确实是使得。
[48:50.680,48:52.380]  我们可以。
[48:52.920,49:4.200]  不用一定存到，不用去关心，就真正那么多的数据调度啊，那么多的这个信息的这些传递的这个过程啊，只关心核心的这个变化逻辑。
[49:4.240,49:6.260]  就可以写出一个。
[49:6.260,49:8.100]  大数据的这个处理来。
[49:8.440,49:9.960]  这个是。
[49:10.320,49:12.780]  第一就是相当于是。
[49:12.800,49:16.140]  第一个这个大数据的这个处理框架。
[49:16.140,49:19.560]  当然，后面还会对他有他的这个发展啊。
[49:19.560,49:22.520]  那么因为它也有很多的这个问题啊。
[49:22.520,49:25.840]  但是他起码他先把这个大数据。
[49:26.140,49:29.960]  这么多的数据的这种变换过程啊。
[49:29.960,49:31.840]  陈，为了这个可能。
[49:32.420,49:33.960]  这是这个。
[49:34.220,49:35.340]  麦produce。
[49:35.840,49:38.840]  就是这个基础的，当然我们。
[49:38.840,49:41.160]  我们可以以word content的这个。
[49:41.160,49:48.460]  这个例子的特点啊，那么或者再理解一下这个例子，那么对这个卖pre丢失这个处理过程啊。
[49:48.460,49:52.080]  那有一定的这个理解啊，特别是这个沙法啊。
[49:52.080,49:53.840]  沙发在干什么啊？
[49:53.840,49:55.500]  那么是要？
[49:55.500,49:57.120]  是要搞清楚的啊。
[49:57.400,49:58.980]  这个。
[49:59.020,50:1.760]  这个搞清楚了，他其实几种。
[50:1.760,50:5.260]  几种粒子，他不同的计算，他那个sop。
[50:5.500,50:10.560]  虽然是有些差别啊，但是但是核心的还是说让所有的一些数据。
[50:10.560,50:12.240]  按照一定的规则。
[50:12.240,50:13.080]  他这么。
[50:13.180,50:15.300]  怎么拧一下啊就。
[50:15.300,50:18.500]  就都能相遇啊，然后就都能。
[50:18.500,50:21.080]  做出做出一定的这个。
[50:21.080,50:22.340]  这个变换处理。
[50:24.920,50:26.360]  嗯。
[50:26.800,50:30.180]  然后就是这个哈，杜普这个。
[50:30.520,50:34.760]  架构在探讨啊，当然这张里面也是。
[50:34.760,50:36.380]  呃。
[50:36.380,50:37.120]  就是。
[50:37.460,50:39.140]  怎么说呢，内容。
[50:39.500,50:40.820]  嗯。
[50:41.060,50:43.640]  相对的要这个。
[50:43.900,50:44.960]  嗯。
[50:45.780,50:53.780]  呃，就是因为你要对这个哈豆腐，原来这个基本的结构基本的晕晕状运行啊，有比较好的理解之后啊。
[50:53.780,50:57.240]  才可以看到，为什么要提升他啊。
[50:58.660,51:0.580]  我们课间休息啊。
[51:27.940,51:30.080]  不用不用不用不用，嗯。
[51:34.060,51:36.640]  嗯，嗯嗯，嗯。

************************************end****************************************

file: 下.mp3
***********************************result**************************************
[0:57.860,1:0.000]  我们来这个继续啊。
[1:0.140,1:5.560]  刚才放的是那个华为在松山湖的那个研发基地啊。
[1:6.400,1:7.580]  嗯。
[1:11.240,1:15.340]  哈吐啊，然后就是哈图的发展呢。
[1:16.140,1:24.240]  他在原来的架构上啊，有一些问题，这里说的架构是指的这个哈舒服1.0啊，它最初开始出来的时候他。
[1:24.240,1:27.440]  先解决这个有无的问题，那么。
[1:27.440,1:29.380]  所以他在这个。
[1:29.380,1:32.460]  呃，这个整个体系上其实。
[1:32.460,1:35.180]  有有各方面的问题吧，啊那么。
[1:35.180,1:36.140]  嗯。
[1:36.520,1:41.700]  在后面哈，都不2.0啊，当然他这也是有一个眼镜过程啊。
[1:41.700,1:45.600]  主要解决了他这几方面的，第一个就是这个a。
[1:45.600,1:48.480]  而且我们也讲过这个概念啊，就是。
[1:48.480,1:50.700]  就是哈微乐宝啊就是。
[1:50.700,1:52.800]  相当于是。
[1:52.800,1:53.600]  呃。
[1:53.600,1:56.900]  保证高可用性啊，就是其实。
[1:56.900,2:0.960]  呃，对在这里解决的话，就是说我的。
[2:0.960,2:3.240]  特别他那个master啊那个。
[2:3.240,2:5.860]  或者什么那个那个那那木。
[2:5.860,2:7.580]  嗯，Name node啊。
[2:7.580,2:9.880]  就是出了问题。
[2:10.240,2:13.320]  那么我还是可以继续。
[2:13.320,2:18.900]  工作的，他用的方法就是有点，我们要把它热双击啊，就是这样的。
[2:18.900,2:23.040]  就是在这个高可用里面啊，这个热双击应该是。
[2:23.040,2:25.020]  最这个比较。
[2:25.440,2:26.560]  嗯。
[2:26.560,2:28.320]  嗯，嗯。
[2:29.740,2:37.640]  就是可用性最高的啊，这样的一种方式了，它相当于一个再有主，主辈在工作，那么。
[2:37.640,2:44.240]  主的这个在工作的时候背的，其实也在做同样的事情啊，他跟这个。
[2:44.240,2:52.060]  这个主服务器之的这个方式和状态差不多，只不过他做的这些都不算啊，只是在边上背着。
[2:52.060,2:56.000]  那么主服务器一旦出了问题，那个被妇幼。
[2:56.000,2:58.560]  被这个被服务器马上就接管。
[2:58.560,3:1.860]  这中间的延迟啊会非常的少。
[3:1.860,3:4.980]  因为我们其实在原来。
[3:4.980,3:5.980]  嗯。
[3:6.380,3:11.580]  就是老的hadoop的机制里面，它有这个name node，也有这个c com name node。
[3:11.620,3:13.720]  她也有主备的形式。
[3:13.720,3:17.020]  那么但是它这种主备呢不是。
[3:17.060,3:19.720]  热双击啊，厨卫的就是冷备。
[3:19.720,3:25.540]  它相当于是我们就是那个叫什么I，有一个MH这样的，这个这个文件啊。
[3:25.540,3:27.780]  那么它包括这个。
[3:27.780,3:36.860]  呃加上这个什么日志啊什么这样的方式，它是定期啊，从主设备我传一份到这个被设备。
[3:36.860,3:39.500]  那么这个定期的这个间隔呢。
[3:39.920,3:41.440]  是比较长的啊。
[3:41.440,3:47.360]  那么当然也也可能跟跟这个设定有关系，但是但是肯定起码是可能。
[3:47.360,3:50.160]  嗯几十分钟啦，小时啦。
[3:50.160,3:52.180]  十几分钟啦，是这样量级的。
[3:52.180,3:54.900]  那么当然这样做他比较。
[3:54.900,3:56.820]  简单啊容易做一些。
[3:56.820,4:5.700]  而这个热备的话，因为它实时的消息，他都要相当于这种处理消息都要从两边发，他用的还是这个日志，小这个日志。
[4:5.700,4:15.820]  通过这个日志向哪边去传他的这个用的这个热备方式，但这个日志他想热备接的，快的话，这个日志文件就是传的非常快。
[4:16.240,4:19.180]  这对他也也涉及到一些这个。
[4:19.180,4:21.580]  一些技术啊这样的一些处理啊。
[4:21.660,4:26.900]  那么祖辈设备的方式还涉及到关于这个。
[4:26.900,4:31.400]  节点到底就是你这个主机到底是不是当了啊，是不是出问题了。
[4:31.400,4:33.640]  他的判断啊在这些判断上。
[4:33.640,4:37.300]  嗯，就这个猪keep啊，他用了这个猪keep的这个。
[4:37.300,4:42.300]  这个机制，这种注册呀，心跳啊，就用用了这样的机制。
[4:42.440,4:45.040]  形成了他的这个a方式啊。
[4:45.040,4:50.040]  完了他另外有这个联邦啊，因为我们这个name node的他的。
[4:50.040,4:58.780]  这个名称节点能服务的这个空间相当于他原来的空间，就是我的目录，在家文件啊，这是他的这个。
[4:58.780,5:4.320]  他的整个的这个命名空间，那文件里面的block，那就是我系统里面自己管的了。
[5:4.320,5:8.240]  这个还是有限的，他又用了这个联邦的方式，相当于。
[5:8.240,5:11.240]  我是其实就是建了多个name node。
[5:11.240,5:14.180]  在上面再加了一层寻址，大概这样的方式。
[5:14.180,5:22.120]  扩大了我整个的管理空间，他家这些实际上当然是为了我可能管的，这这都不是PB了啊。
[5:22.120,5:27.180]  嗯，原来一个level的管PB是就是一个name node，管PB应该。
[5:27.180,5:28.880]  是还是可以的啊。
[5:28.880,5:31.140]  那么他可能是。
[5:31.140,5:31.980]  就是。
[5:32.560,5:37.460]  相当于接近什么CD啊什么，还是这样的数据要用到它的联邦。
[5:37.500,5:43.660]  这是一部分的改进，还有一部分就这个烟啊，因为原来就他的这个资源调度。
[5:44.120,5:50.080]  这也是它里面挺重要的一个体系，但是在原来的1.0里面。
[5:50.160,5:57.040]  他的就是相当于文件管理的这些资源调度和它的计算，就是produce啊这些的。
[5:57.040,6:2.060]  资源调度啊，在他体系里面是一个一个东西，就他自己在。
[6:2.060,6:3.040]  体系在管。
[6:3.040,6:5.460]  那么这个是带来了。
[6:5.460,6:9.660]  呃也有很多这个独立或者方面啊，所以他有。
[6:9.660,6:15.520]  就提供了一个就是1h a der这个resources什么。
[6:15.520,6:18.400]  这个卖的这个艳艳就是这样的意思。
[6:18.400,6:23.760]  它实际上是把这个资源标注的各种情况，在分在分一些啊，分了之后。
[6:23.760,6:27.960]  就是卖produce的计算，是卖produce的计算那个。
[6:27.960,6:30.200]  那个。
[6:30.200,6:35.020]  HHS啊，这些存储的这些地方的调度，因为他们俩。
[6:35.020,6:42.900]  这个要能用到的这个资源，包括map reduce里面的迈普的任务啊，还有什么reduce的任务啊，就是这些。
[6:43.520,6:54.280]  嗯，原来这种太绑定了，实际上你的资源分配，像他在原来那个方式里面准备的这个节点啊，我他要分出map节点来，Reduce节点来。
[6:54.280,6:57.640]  这个时候你你如果这个任务迈步节点。
[6:57.640,6:59.900]  卖出很多reduce比较简单。
[6:59.900,7:3.140]  那么但是他可能有些人就节点，它就用不上。
[7:3.320,7:12.260]  就是这些事都是老的这个机制带来问题，他当然也可以把reduce改成map节点，但这个改是要是要带假的啊。
[7:12.260,7:13.300]  那么。
[7:13.360,7:21.780]  他他要要花费，要花费时间，可能也许都要重启，重启这个机器才能，才能改才能比较好的改过来。
[7:21.780,7:23.960]  那么油压呢确实就。
[7:23.960,7:27.900]  更灵活了，而且我们后面也可以看到这个亚运的这个机制。
[7:27.900,7:28.880]  他是一个。
[7:28.880,7:31.680]  一乡一定程度上是一个。
[7:31.680,7:34.700]  通用的这个资源调度的这样的一个形式。
[7:34.720,7:38.060]  而且包括这个呀和这个猪keep啊。
[7:38.060,7:39.140]  嗯。
[7:39.140,7:41.380]  之间的这样的一些配合。
[7:41.380,7:43.180]  他她慢慢把这个。
[7:43.180,7:46.280]  一按这些，他更多的作为是资源调度的。
[7:46.780,7:52.100]  因为资源还分为这个调度和监控啊，这样两种层面，一个就是。
[7:52.100,7:53.100]  一个就是。
[7:53.120,7:59.660]  嗯，其实说起来就是老大，这个是关，就是到底谁干这个事情，谁干这个事情他说了算。
[7:59.660,8:1.820]  但是这个事情干得好不好呢？
[8:1.820,8:6.160]  就得有一个秘书长来帮这个，帮这个老大啊或者。
[8:6.160,8:13.320]  就是以前可能最早简单一点，都都老大一个人管啊，他既然分分了你，你好不好，是不是。
[8:13.320,8:22.640]  好不好好好干活也老大在盯着，然后是不是这个出了问题，我赶快要换个资源给你，也是老大盯着，这个时候老大就。
[8:22.640,8:25.500]  忙不太过来啊，其实事情反而没干好。
[8:25.500,8:27.760]  那么现在就是分成了。
[8:27.760,8:30.520]  这个老大就老大，还有这个。
[8:30.520,8:32.420]  朱K吧搞了一个。
[8:32.420,8:38.120]  这个助理或者这个预装，因为监控这个事情当然也有他难的地方，但是。
[8:38.120,8:46.060]  从这个智能上啊，这个方面逻辑上相对要简单一点监控，你只要有责任心啊，始终盯着就可以。
[8:46.060,8:47.680]  那么就。
[8:47.680,8:49.180]  就搞得这个。
[8:49.320,8:51.640]  大概这个猪keep的这个体系。
[8:51.640,8:53.540]  那么这样拆开之后。
[8:53.540,8:58.560]  使得这个hadoop体系，它的这个开放性啊，他的这个。
[8:58.960,9:1.020]  兼容的这种能力。
[9:1.020,9:8.100]  嗯就更好了，而从而在他的基础上啊，有了进一步的这些发展啊这些。
[9:8.100,9:14.120]  这些spot了，在各种主见啊，也都容易把它再再组组合进来。
[9:14.120,9:16.100]  这时是一个2.0，它就。
[9:16.200,9:18.180]  也是像开放性。
[9:18.260,9:21.440]  上面去发展，这是1.0和2.0。
[9:21.440,9:24.960]  对于这个哈豆腐架构啊上面的。
[9:24.960,9:26.480]  呃，一种演技。
[9:26.880,9:28.140]  嗯。
[9:28.140,9:35.400]  那这部分就是啊，介绍完了是相当于啊哈杜普啊，它整个的这个发展。
[9:35.400,9:36.720]  眼镜就。
[9:36.720,9:37.920]  就做完了。
[9:38.060,9:42.920]  嗯，而且这些部分现在相对的比较稳定了。
[9:42.920,9:45.820]  而很多的，在很多的发展。
[9:45.820,9:46.960]  这个。
[9:46.960,9:49.280]  嗯啊，这个害我还不是啊。
[9:49.380,9:51.100]  嗯，先把这孩子说完。
[9:52.340,9:57.420]  Hive呢，就是我们下面说了hadoop这三驾马车啊这些。
[9:57.420,10:3.600]  计算也有了，存储也有了，当C口也有啦，X也有了，但是咱觉得。
[10:3.600,10:5.200]  这个东西没有。
[10:5.200,10:7.960]  没有这个没有C口啊。
[10:7.960,10:9.520]  还是不方便啊。
[10:9.540,10:11.840]  那么没有C口还是不方便。
[10:11.840,10:16.960]  一定存壮士，对应的是这个，就是所谓的这个数据仓库。
[10:16.960,10:20.980]  这这种这种需求这种整理实际上是一种。
[10:20.980,10:31.420]  大数据量的这个分析啊，这个这个报告啊的，包括把商业智能啊，就这些原来其实在传统的那些数据库上，这行业也在做。
[10:31.420,10:35.660]  但是大数据起来之后，那么没有相应的这些。
[10:35.660,10:36.540]  这些方法。
[10:36.580,10:38.020]  所以在这些。
[10:38.020,10:40.640]  是一个推动下啊，就是这种。
[10:40.640,10:43.900]  在大数据上怎么来提供这个？
[10:44.700,10:47.840]  随口能力当然只是一个标记了，实际上只。
[10:47.840,10:50.980]  综合起来就会把它看成是一个数据仓库的。
[10:50.980,10:52.460]  这样的这个能力。
[10:52.460,10:55.220]  那么所以才有了这个。
[10:55.220,10:57.260]  嗨，五这样的这个。
[10:57.260,11:0.640]  这个出来当然嗨，五实际上，嗯。
[11:0.740,11:3.640]  说的他有点也不说有点。
[11:3.920,11:4.960]  有点。
[11:5.880,11:9.720]  贼吧，他他是用了一个这个集成的方式啊。
[11:9.720,11:17.880]  或者这个偷懒的方式来把这个做出来的，我们在这里面分析过他怎么，他实际上底层还是卖produce。
[11:17.900,11:20.880]  啊，他他是把这个C口。
[11:20.960,11:28.980]  去通过这个语言解析啊，就这样的一些能力啊，把他最后把它解成了这个map reduce的任务。
[11:29.080,11:34.200]  那么发给还是发给这个hadoop mapreduce这个框架来做啊。
[11:34.200,11:39.120]  那么在这么搭起来，他也能工作，当然为了这个再嗨我自身他有。
[11:39.120,11:48.360]  他有他的这个就是语言解析的东西，他要存他的这个原数据啊，所以还有工作，他妈自己还要配一个关系数据库啊。
[11:48.360,11:53.160]  MYSQL把这个原数据存在里面，这个原数据存在里面就是。
[11:53.160,11:59.540]  去表明我的表啊字段啊，这这都是这都是C口语言所必须的东西啊。
[11:59.540,12:0.480]  那么。
[12:1.220,12:2.940]  怎么定义的，那么？
[12:2.940,12:10.960]  那么你一个cpu语句发过来，我从这个原数据找出这些定义，再把你的语法C口语法解析变成了。
[12:10.960,12:16.740]  我们说过什么，那个就格爸呀，这个就这样的一些。
[12:16.740,12:19.300]  这个还有噪音的，这个就是。
[12:19.320,12:24.900]  教育的这种查询，这都是对C口相对还是有点难的，这样的。
[12:24.900,12:27.140]  就是比较的这个C口语句。
[12:27.140,12:31.840]  那么怎么用map reduce去就怎么翻译成mapreduce的动作啊这是？
[12:31.840,12:37.000]  我们稍微介绍一下，总的来说就是嗨舞是用这样的一个方式。
[12:37.000,12:37.760]  啊。
[12:37.760,12:41.580]  通过对C语言的解析，翻译成map reduce的。
[12:41.580,12:44.260]  这个的一个的教具。
[12:44.520,12:45.580]  Jump。
[12:45.580,12:46.940]  慢慢来。
[12:47.140,12:49.780]  执行的一个。
[12:49.780,12:52.960]  方式，当然这个方式就会有一定的。
[12:52.960,13:2.740]  若点啊，当然这个弱点呢，像在商户数据仓库的很多应用上可能也能接受啊，这这个就首先它就比较慢啊，因为卖produce。
[13:2.740,13:4.760]  本身它就比较慢啊。
[13:4.800,13:9.140]  那么他他能出力大的数据，但是他必须是。
[13:9.140,13:13.480]  一批一批的处理，第二呢，就是它这个翻译出来的过程。
[13:13.480,13:14.960]  他的一个。
[13:15.560,13:26.960]  一个C口就是说，或者他一些一些C口这些语句查询，肯定是要翻译成多个这个mapreduce的任务来做，但是他在上面有点这个调度的意思啊，他把这多个卖reduce。
[13:26.960,13:28.860]  任务都能调度下来。
[13:28.860,13:34.820]  嗯，但是这样的话总的来说还有缺陷，所以又有这种import。
[13:34.820,13:36.520]  In啪啦啊，就是。
[13:36.700,13:38.600]  就这样的这个。
[13:38.600,13:40.660]  分布引擎来做。
[13:40.660,13:43.380]  那么它实际上就比这个。
[13:43.380,13:45.740]  嗯，害就高。
[13:45.740,13:46.700]  高很多。
[13:46.700,13:55.980]  就性能要高很多啊，因为他不是用max juice来做的，他就是相当于实现了基本上在这个大数据啊，这个基础上。
[13:56.500,13:59.620]  存储这个大数据基础上，它实现了一个。
[13:59.620,14:2.680]  就是C口C口引擎的这样的一个东西。
[14:2.680,14:9.480]  有点像分布式的seo引擎，但是它跟Hao之间的做法还是也有类似的，他前面那些。
[14:9.480,14:12.460]  语言解析就C口解析啊，什么这一部分。
[14:12.460,14:14.300]  他是跟hi类似的。
[14:14.300,14:18.700]  那么只不过他把这些解析出来之后就直接。
[14:18.700,14:20.780]  放到自己的引擎里面啊。
[14:20.780,14:23.340]  去完成了，那么这个引擎。
[14:23.340,14:24.820]  他比这个。
[14:24.820,14:27.100]  你们reduce的这些方式呢？
[14:27.180,14:29.620]  呃的这个执行。
[14:29.660,14:32.900]  效率要要高啊，这是影。
[14:32.900,14:33.860]  京趴了的。
[14:33.860,14:37.520]  但是引发了咱自身的这个引擎怎么把这个。
[14:37.520,14:38.260]  嗯。
[14:38.260,14:40.220]  执行下来啊，这个我们。
[14:40.220,14:41.900]  没有细的去。
[14:42.000,14:44.620]  去这个去讲解研究。
[14:44.620,14:47.560]  但是后面我们觉着可以去参考这个。
[14:47.560,14:55.600]  Spot他他跟spark当然是不一样的，但是他肯定是他用了更多的这个内存方面的这些一些方法。
[14:55.600,14:57.680]  来做出这样的。
[14:57.680,15:0.080]  对这个cpu语言的这个。
[15:0.080,15:2.300]  姐适合这个支持。
[15:2.940,15:5.200]  这是害法。
[15:6.920,15:8.300]  嗯。
[15:8.300,15:12.400]  所以他对他有这个比较更高的这个效率。
[15:12.400,15:19.820]  所以他有可能呢，能支持这个实时的这样的这个计算啊，就成为这个哈图补上的一个。
[15:19.820,15:21.640]  实时计算的平台。
[15:21.920,15:23.220]  呃。
[15:23.220,15:28.160]  当然我们对对hive本身啊，Hive他有这个。
[15:28.160,15:32.760]  呃对，他可以类似用一些，他也自己有这个语言接口啊。
[15:32.760,15:33.620]  就是。
[15:33.620,15:35.560]  自身的这个命令行的接口。
[15:35.580,15:38.360]  呃提供了一些。
[15:38.800,15:44.000]  就是访问的这样的这些API啊，当然他也可以有这个。
[15:44.000,15:44.920]  嗯。
[15:44.920,15:45.940]  嗯。
[15:45.940,15:47.560]  就是其他的这种。
[15:47.560,15:48.380]  最终。
[15:48.380,15:53.160]  访问的接口用这个程序的这个方式啊，来打包访问。
[15:53.160,15:58.420]  他提供的这个访问能力啊和一个数据库啊，对外提供的一个访问能力是。
[15:58.420,16:0.060]  是非常类似的啊。
[16:0.060,16:1.960]  这样的话就是。
[16:1.960,16:5.800]  呃，就使得这个大数据这套体系啊。
[16:5.800,16:7.580]  有可能就像。
[16:7.640,16:13.120]  呃，就是访问一个这种传统数据库那样的方式啊去。
[16:13.120,16:14.640]  去应用它。
[16:14.640,16:20.920]  呃或者这样的去使用它，当然你说他跟那个什么，呃开普的这个。
[16:20.920,16:22.820]  之间的矛盾，那么。
[16:22.820,16:28.460]  它的它上面就是真正的用起来，如你同时又是很大的这个表。
[16:28.460,16:34.440]  然后又是用很复杂的数据去操作，它肯定是有还是有很多使用上的限制。
[16:34.720,16:39.300]  大量的应该是他在事物上啊什么，这些上面的一些限制我们。
[16:39.320,16:41.200]  在啊对，前面还没提。
[16:41.280,16:50.640]  前面说到这个什么cap理论和这个数据库的理论上面，还有就是就是关于那个事务性的啊，这个几个原则啊。
[16:50.640,16:51.860]  我们是要。
[16:52.140,16:57.000]  呃离呃知道有这么一个事情啊，当然害怕他支持C口，但是在。
[16:57.000,16:58.920]  输入性方面肯定是。
[16:58.920,16:59.960]  有所限制的。
[17:2.040,17:3.780]  好，那么。
[17:4.280,17:7.980]  汉武这样完了的话，就相当于还是在。
[17:7.980,17:11.860]  这个传统的这个hadoop这个体系下啊我们。
[17:11.860,17:21.080]  就整个的各个方面的功能就匹配的差不多了啊，包括这个最后我这个C接口啊，那么我通过hive转。
[17:21.080,17:23.520]  麦produce的这样的一种方式。
[17:23.520,17:25.820]  也把他这个提供出来了。
[17:25.940,17:30.560]  呃，那么在后面的这个spark就出来了就是。
[17:30.560,17:33.100]  相当于是针对这个。
[17:33.860,17:36.780]  Produce或者从计算框架上啊。
[17:36.780,17:37.820]  他又。
[17:37.820,17:40.400]  整个的提升了一程，嗯。
[17:40.460,17:42.140]  那么我们。
[17:42.360,17:44.820]  嗯，这是这个。
[17:45.120,17:50.700]  Spark的啊，这个他也讲这个生态啊，当然spark生态上也是。
[17:50.700,17:58.880]  有各种各样的东西，他自身也有一个他资源管理的东西，它可以构架在hadoop的这个资源管理的燕莎。
[17:58.880,18:0.760]  他也可以用自己的这个。
[18:0.760,18:1.980]  买手撕啊。
[18:1.980,18:4.060]  是这个就是。
[18:4.060,18:5.300]  Spark这套。
[18:5.360,18:7.640]  这套这个开源体系下。
[18:7.640,18:8.340]  他。
[18:8.340,18:9.960]  做的一个。
[18:9.960,18:11.440]  一个管理框架啊。
[18:11.440,18:12.920]  那么。
[18:12.920,18:17.780]  他也可以用到一些内存，内存持久化的这样的一些东西。
[18:17.880,18:20.100]  那么在他上面啊。
[18:20.100,18:22.060]  还会提供这个。
[18:22.060,18:24.380]  崔敏啊，这个。
[18:24.380,18:25.520]  嗯。
[18:25.560,18:27.960]  C口啊图形。
[18:27.960,18:37.780]  机器学习啊，还有各种功能的库，就是这个图上可以看出来，就是spark，它也是发展了一套，这个非常完整的体系。
[18:37.780,18:41.380]  这是因为它包括性能更好啊就有。
[18:41.380,18:44.160]  这些这些方面的特点啊所以。
[18:44.160,18:51.040]  呃，很多人就是愿意啊在上面来发展，包括这个水平层次上啊，我们可以。
[18:51.040,18:53.780]  直到这个虚拟化的一层。
[18:54.440,19:0.280]  然后有存储，然后有具体的处理啊，处理是他最核心的这个计算的这个部分。
[19:0.280,19:1.500]  然后他是。
[19:1.500,19:4.900]  在上面提供的各种这个包装的这个能力。
[19:4.900,19:6.820]  这是这个sponsor。
[19:6.820,19:7.600]  对。
[19:7.760,19:8.600]  体系。
[19:9.060,19:10.440]  体框架。
[19:10.440,19:11.380]  当然。
[19:11.380,19:14.200]  是以这个为核心的，他这个叫。
[19:14.200,19:15.180]  嗯。
[19:15.180,19:18.360]  BBS啊，因为这是那个。
[19:18.360,19:21.840]  嗯，加州的那个玻璃啊。
[19:22.300,19:25.180]  伯克利大学他们发展出来的体系啊。
[19:26.100,19:27.540]  嗯。
[19:29.040,19:34.580]  在这个对spark的理解上面，首先就是核心就是他怎么。
[19:34.580,19:42.600]  嗯去解决这个卖produce的问题，或者说卖produce，在这个计算处理框架上。
[19:42.600,19:46.200]  嗯，那么有哪些问题，那么他又会。
[19:46.200,19:49.920]  怎么来，怎么能把这些问题解决掉啊，这是。
[19:49.920,19:52.480]  这是对这一部分最核心的。
[19:52.480,19:53.640]  这个。
[19:53.640,19:57.280]  呃或者理解要认知的地方。
[19:57.420,20:9.560]  嗯，那么mapreduce我们前面已经说了，他起码是提供了一个这么大量的数据啊，你可以对他进行处理啊，那么他用这个suffer啊，这样的机制来进行处理。
[20:9.560,20:11.480]  但是他他有他的问题啊。
[20:11.480,20:12.360]  那么。
[20:12.420,20:15.820]  首先呢一个很严重的问题就是。
[20:15.820,20:18.680]  他的处理过程卖produce。
[20:18.680,20:20.180]  的处理过程。
[20:20.180,20:22.080]  他很多是基于文件的啊。
[20:22.160,20:26.140]  因为他当然也用到了内存啊，但是他最后。
[20:26.140,20:28.560]  的这个，嗯。
[20:28.560,20:37.960]  就是他在内存的话，它是大概相当于一个一个小缓存的一个概念啊，他最终处理啊，内容的这个交换啊就是。
[20:37.960,20:39.980]  中间的这个。
[20:39.980,20:41.040]  这些。
[20:41.040,20:45.220]  结结果啊，就是map和这个reduce的。
[20:45.220,20:48.260]  这个中间的这些交换，他都是经过文件。
[20:48.260,20:49.600]  来进行传递的。
[20:49.600,20:53.060]  这样的话会使得它的性能。
[20:53.060,20:56.680]  嗯，受到了很大的这个制约啊相当于。
[20:56.680,21:0.940]  而这个spa在这点上，他就是用了这个RD啊。
[21:0.940,21:4.160]  这是他的一个特点用的啊，弟弟。
[21:4.160,21:5.820]  这样的一个。
[21:6.060,21:9.240]  啊，只能生成，不断生成。
[21:9.260,21:11.820]  新版本的。
[21:11.820,21:17.360]  呃，而不能去到中间去修改的，这样的一个内存。
[21:17.360,21:18.480]  内存。
[21:18.480,21:20.200]  块儿的使用技术。
[21:21.040,21:28.140]  而使得他对这个整个这个内存的处理，那包括去解决到他的就是。
[21:28.160,21:32.840]  就是mapreduce它内存为啥不用到这么底线应该。
[21:32.840,21:35.200]  也是有它的原因的，就是。
[21:35.200,21:41.900]  就是相当于我在这么大量这么复杂，交互完了，又想共享的情况下。
[21:41.900,21:43.200]  去用内存。
[21:43.200,21:52.280]  会有会有，很会有很多的制约，所以他只是在中间的各种处理片段，让你自己在这些处理片段那啊。
[21:52.280,22:1.560]  自己拿一些内存作为作为缓存，你的迈普啊，你的他耶，迈普的这么一个单个的计算过程，那我可能去做一些。
[22:1.560,22:7.780]  我当然在内存里面做一些缓存，做一些计算，我们还都讲过这个map的处理过程中。
[22:7.780,22:12.000]  然后他不断的这个一写啊，它就是相当于内存缓冲区。
[22:12.000,22:12.720]  嗯。
[22:12.720,22:18.680]  处理的过程中，然后内存缓存用完了，它就一写出一写出文件来，一写出文件来。
[22:18.680,22:19.500]  事实。
[22:19.680,22:22.320]  它实际上它还是就是。
[22:22.320,22:23.800]  简化了。
[22:23.800,22:26.920]  就是用内存最基本的这样的功能啊。
[22:27.100,22:32.320]  而spa就是用ID的这样的方式使着这些内存的，他可以。
[22:32.320,22:35.560]  共享可以在不同的处理结果之间啊。
[22:35.560,22:36.500]  来。
[22:36.500,22:42.040]  来这个共享内存，但是他为什么能用到这一点，适合他把这个IPD。
[22:42.040,22:44.620]  特定的做了它的定义，我只。
[22:44.620,22:47.700]  重新生成我不修改，他这样的话。
[22:47.700,22:49.880]  就是让这个。
[22:49.880,22:51.560]  呃，共享那就。
[22:51.560,22:52.840]  就成为可能。
[22:52.840,22:56.400]  这个是spark最核心的。
[22:56.400,22:59.000]  呃，一块啊，这样的话他。
[22:59.000,23:1.220]  他有大量的东西，它是可以在。
[23:1.220,23:3.500]  可以在内存上来进行。
[23:3.500,23:4.800]  进行计算的。
[23:5.220,23:15.820]  当然它也有就内存放不下，内存放不下，他是靠，他是靠ABCD这样来整片的，来轮询啊，那么我这样的话处理，最后我处理这几个ID，我就把这个R。
[23:15.820,23:20.540]  这个ID的整个把它弄好，弄完了之后，我这个ID的啪就。
[23:20.540,23:23.800]  就一个ID，我就刷刷到这个磁盘上去。
[23:23.840,23:25.420]  但是他还有。
[23:25.420,23:28.660]  这些很多的用法，包括他还用了一些。
[23:28.660,23:32.180]  内存持久化的方案，这都可能跟他的不同的。
[23:32.180,23:37.840]  配置相关，这些都能很好的提供，提供他的就是提升他的这个性能。
[23:37.840,23:41.320]  所以使得这个spot的技能比这个。
[23:41.320,23:42.460]  嗯。
[23:42.460,23:45.260]  高很多啊，就是比那个。
[23:45.980,23:48.500]  麦produce啊，在这个。
[23:48.940,23:50.420]  强计算方。
[23:50.420,23:54.220]  就是很正计算的这样的领域，他的这个。
[23:54.220,23:57.920]  性能高很多，我们举个例子就是拿它来。
[23:57.920,24:2.320]  排序啊，他可能要高上百倍的，大概的这个。
[24:2.420,24:3.820]  呃，样子。
[24:4.400,24:14.360]  嗯，那个stopped就是mapreduce，当然还有其他的问题啊，那么还有一个问题，就是它的那个计算框架，它就是卖produce。
[24:14.360,24:16.420]  所有都是这样的一个任务。
[24:16.420,24:22.900]  这个咱当然是这个基本能力是有了，你在上面编程，也可以有各种强大的表达能力。
[24:22.900,24:26.420]  但是确实很多事情不是这么一步就能搞定的。
[24:26.420,24:35.440]  所以很多用它，你像包括海威啊，很多人用它的话就得自己去去调度啊，把这个麦克丢死去，组合起来。
[24:35.440,24:40.260]  在这样的调度中，还是也是有损失的，因为它本身就是个文件传递。
[24:40.260,24:43.640]  你的多个map reduce之间更是文件传递。
[24:43.640,24:45.260]  那么这个。
[24:45.260,24:47.400]  这个文件传递还甚至。
[24:47.400,24:50.680]  包括他很多可能要通过HDFS啊来传递。
[24:50.680,24:55.120]  这这些呢，都是对他这个资源上能力上的有消耗。
[24:55.260,25:1.340]  而所以这个spot他提供了这种叫我们说有这个有像。
[25:1.340,25:5.320]  这个无关图啊，这个什么bab啊这样的一个概念。
[25:5.320,25:9.960]  实际上它就是它的处理的逻辑步骤之间能进行组合。
[25:9.960,25:16.640]  那么当然他组合的原则还有什么，这块链接在链接，那么有这样的也有一些。
[25:16.640,25:21.740]  这样的概念之后，所以他对整个这个组合的这个步骤。
[25:21.740,25:22.960]  还能优化。
[25:22.960,25:29.780]  嗯，而且结合到他啊弟弟的这个特点啊，所以他很多的这个步骤的话，他可以把他。
[25:29.780,25:31.440]  画成这样的一部。
[25:31.440,25:35.720]  这一步里面它就可以做到，我就是在内存里面。
[25:35.720,25:38.040]  就就就整个的在。
[25:38.040,25:41.860]  在进行这个把我前面处理的结果。
[25:41.860,25:44.240]  传递到后面去用啊。
[25:44.240,25:45.760]  这样的话是。
[25:45.780,25:49.120]  这都是当然以ad为基础，而且。
[25:49.120,25:51.500]  呃使得spa在这个。
[25:51.500,25:55.560]  数据的这个多部的这个处理过程中。
[25:55.560,26:5.660]  他可以有更强的能力，实际上他就是能有这种数据处理的这种流程，而这个流程还可以进行这个组合。
[26:5.660,26:6.880]  进行优化。
[26:6.880,26:7.960]  那么。
[26:7.960,26:10.760]  这样的话原来你做一个事情。
[26:10.760,26:15.840]  用的map reduce，就是逻辑复杂一点的话，卖produce掉很多遍。
[26:15.960,26:21.440]  嗯，儿用spot的话，可以用一个优化组合的逻辑。
[26:21.440,26:23.420]  拿这个啊，弟弟啊。
[26:23.560,26:27.500]  由他系统帮你找到这个优化组合的地方。
[26:27.500,26:29.920]  嗯，来来做几遍就。
[26:30.820,26:32.020]  就完成了。
[26:32.060,26:34.320]  这个是这个。
[26:34.320,26:37.320]  嗯，就是spark。
[26:37.320,26:38.900]  比这个。
[26:38.900,26:41.360]  麦produce，或者比这个传统的。
[26:41.420,26:44.000]  Hadoop的处理的这个。
[26:44.000,26:55.260]  机智上好的地方，所以spark现在的这个应用啊，这热度呀，也可能比这个mapreduce高很多啊，但是当然很多，他因为也有。
[26:55.280,27:0.280]  在这个map hadoop上，也有很多已经现成的东西啦，所以。
[27:0.280,27:5.920]  他们往往是把这些东西结合起来用的，包括像我们的实验平台就是。
[27:5.920,27:10.240]  这个spot应该就是装在这个哈哈，豆腐这个机制上的。
[27:10.280,27:16.800]  他应该也是用呀来管的，所以这个像我们启动的过程都知道，要先把这个。
[27:16.800,27:20.580]  先把即便起起来，先把豆腐起起来，再起这个。
[27:20.580,27:22.920]  再去我们的这个spark啊。
[27:23.160,27:26.380]  这是他处理的方面。
[27:26.620,27:27.980]  嗯。
[27:28.600,27:30.160]  我看啊，这里。
[27:30.160,27:32.460]  但是他有了这些处理的。
[27:32.780,27:35.720]  那方便之后啊，还可以看他的这个。
[27:35.800,27:37.460]  这个处理的结构。
[27:37.460,27:44.280]  有这样的一份子处理能力，而使得它也能做更多的事情，比如他有这个spot trading啊。
[27:44.280,27:48.940]  就是他用一些小步快跑的方式啊，能支持这个stream。
[27:49.040,27:56.080]  呃就是在这里，当然也是相对相应的回顾一下，就是大数据应用的领域啊。
[27:56.180,28:6.580]  那么有这种流失处理的啊，有这种分析处理的，这这就叫C口答，跟这个数据仓库啊，什么和这些对应的，还有这种。
[28:6.580,28:8.600]  图计算的还有就是。
[28:8.600,28:12.220]  继续学习的啊，就有这样子不同的。
[28:12.220,28:13.980]  这个大数据。
[28:13.980,28:15.120]  应用的领域。
[28:15.120,28:17.220]  这些领域当然都是。
[28:17.220,28:22.680]  由这个我们知道这种海量的数据啊什么，这些已经能有能生成在。
[28:22.860,28:23.920]  嗯。
[28:23.920,28:26.440]  能放到系统来这个基础上啊。
[28:26.440,28:28.500]  我们来发展出来。
[28:28.500,28:29.320]  就是。
[28:29.320,28:30.960]  上面的这些这个。
[28:30.960,28:33.780]  呃运用的这个模式啊。
[28:34.140,28:39.920]  而这个司法体系就是对这些模式呢，也都有这个。
[28:39.920,28:42.360]  呃支撑和这个。
[28:42.360,28:43.280]  嗯。
[28:43.280,28:46.440]  呃，就是或者这种资深的这个解决方案啊。
[28:46.620,28:50.220]  嗯，对，包括在这里面说的还有那个。
[28:50.600,28:51.920]  像那个。
[28:51.920,28:55.860]  嗯，Spot对这个。
[28:55.880,28:57.460]  C口的支持啊。
[28:57.460,29:1.300]  他原来有一个一个shock的这这个方案。
[29:1.320,29:4.900]  那么沙克方案他就有点像那个。
[29:4.900,29:6.160]  嗯。
[29:6.280,29:9.000]  就是它有点像那个hype啊。
[29:9.000,29:12.900]  就是相当于是我用那个。
[29:12.900,29:14.300]  呃。
[29:14.760,29:16.660]  我用那个。
[29:18.020,29:20.240]  嗯，语法解析。
[29:20.240,29:29.320]  那么包括加上我的这个原数据的这样一些一些存储，然后爸我的这个。
[29:29.440,29:34.340]  呃SQL语言啊，转化成这个spot的。
[29:34.340,29:36.740]  这样的一些一些任务哈。
[29:36.740,29:37.820]  那么。
[29:37.860,29:38.760]  他。
[29:38.820,29:42.580]  他但是他原来的那个方法上就是sop上。
[29:42.580,29:50.140]  他就是他底层就spark没改的，所以会带来一些一些问题，后面还出来了这个。
[29:50.140,29:55.240]  发sql blink DB啊，有这样的方法，相当于他在。
[29:55.240,29:57.220]  最终的这个。
[29:57.220,30:0.680]  嗯，C口啊就是转化出来的。
[30:0.680,30:3.220]  解析，执行上面啊，是。
[30:3.220,30:3.920]  有。
[30:3.920,30:7.220]  自己的一套低至掉spot更底层的东西啊。
[30:7.660,30:9.800]  自己直接把它完成了啊。
[30:9.960,30:12.400]  这个是。
[30:12.580,30:15.800]  这都是跟spa相关的啊一些。
[30:15.820,30:17.480]  运用的这些情况。
[30:17.940,30:19.160]  嗯。
[30:20.140,30:21.420]  那么。
[30:21.500,30:27.080]  Sox这部分介绍完了，后面我们再来看，就涉及到这个流计算啊。
[30:27.080,30:28.760]  流计算里面呢。
[30:29.760,30:34.920]  我们首先要知道就是大概是流计算的，这样的一种。
[30:35.100,30:38.520]  一种概念啊实际上是就是。
[30:38.520,30:40.580]  我们说到过这事跟。
[30:40.580,30:43.120]  现实世界，也许一种更。
[30:43.120,30:46.720]  更真的这种现实世界的一种反应啊，因为。
[30:46.720,30:54.540]  我们现实世界其实各种信息，但是在物理规律啊，就这些规律的作用下，就不断的在变化，再往前走的。
[30:54.600,31:0.620]  我们原来的计算机的体系，计算机的领域，只能做到对这些信息。
[31:0.620,31:3.180]  抽取一部分这个节点。
[31:3.200,31:6.080]  这个什么就是叫什么。
[31:6.080,31:7.480]  嗯，嗯。
[31:7.740,31:13.720]  就像照相似的，啊就是一个快照啊，就其实是某些片段的这些值。
[31:13.720,31:24.300]  完了把这些值存储起来，我们整个的历史的这个数据分析啊，我们数据仓库啊，很多传统的这些应用都是在这个基础上进行的。
[31:24.300,31:29.940]  当然始终核心这一块，还有一部分是计算机跑的应用，啊你这个卖东西啊什么。
[31:30.180,31:36.620]  是行程这些东西，但是大数据这个领域，其实在这一块，呃一直是介入的比较少的。
[31:36.660,31:42.580]  但是慢慢的就是这么的发展出来，就是我是可以把它这个。
[31:42.660,31:43.400]  是。
[31:43.400,31:49.760]  就包括这这跟随的这个物联网这些技术发展都有关系啊，我就把这个现实的。
[31:49.840,31:52.140]  世界的这些信息。
[31:52.140,31:54.000]  就实时的把他抬进来。
[31:54.220,31:56.160]  完了我要进行处理。
[31:56.160,32:0.100]  这就是这个刘处理的这样的这个概念那么。
[32:0.100,32:5.120]  那么这样的话，我要处理的不是以前的快照是的这个片段的东西。
[32:5.120,32:13.400]  而是不断进入到系统中的这样的信息啊，当然未处理这个它也有一些限制啊比如说。
[32:13.400,32:15.400]  我就是处理完了。
[32:15.480,32:19.000]  嗯，也不是说限制，就是根据这个。
[32:19.000,32:21.280]  当时的这个技术条件啊。
[32:21.280,32:21.940]  就是。
[32:21.940,32:24.980]  自己加了一些限制，我我就是。
[32:24.980,32:32.960]  编数据编进来，我就边处理边处理，我就有一些结果，这些结果当然大家可以去查而处理不了的。
[32:32.960,32:35.820]  没过的东西我就把它丢掉了啊，这样是避免。
[32:35.820,32:36.780]  存储。
[32:36.780,32:38.940]  太大，这是流数据。
[32:38.940,32:49.340]  但是所有这些呢，就是说从这个信息流啊，这些数据流的基础上，就有了这样的这个留的概念，它是源源不断的始终在进行的。
[32:49.340,32:52.620]  那么对这样留的这个处理其实就是要求。
[32:52.720,32:54.240]  你的这个处理。
[32:54.240,32:55.260]  这个非趁。
[32:55.260,32:56.480]  你不能有延迟。
[32:56.480,32:58.760]  那么因为延迟了就会堆积。
[32:58.760,33:2.120]  堆积了越堆越多，那你是搞不定的啊。
[33:2.120,33:9.040]  原来那个快照那个没关系，就是我们原来那个方法，我反正照照一点照一点就是。
[33:9.040,33:10.040]  那么。
[33:10.040,33:11.860]  自自我把它还。
[33:12.580,33:16.820]  快照的这一部分嘛，穿出来当然那样子也已经很大量了。
[33:16.820,33:21.100]  也所以还要有卖produce呀，什么样的方式。
[33:21.100,33:24.980]  来批处理的那处理那样的快照的信息。
[33:24.980,33:28.400]  那留更是啦，那么不断的流进来。
[33:28.400,33:32.440]  就不能有延迟这样的，对这个计算呀，处理结构都有。
[33:32.440,33:33.980]  都有这个要求啊。
[33:33.980,33:37.920]  那么就核心，就是我一定就能实时处理完。
[33:37.920,33:38.720]  刚才。
[33:38.860,33:44.960]  呃，这个确实就是说过的这个带来的挑战就是这种分值和评分的挑战啊。
[33:44.960,33:45.920]  大家。
[33:45.920,33:50.640]  也讲过这个这个例子啊就是。
[33:50.760,33:56.580]  嗯，你如果要想达到完全的这个流，处理这种的能力的话。
[33:56.580,34:0.920]  就是你必须得应付最高分的这种能力。
[34:1.180,34:3.480]  所谓最高分的能力就。
[34:3.480,34:4.860]  像那个什么。
[34:4.860,34:10.920]  双11的这种促销啊，就是在这个最高分的时候，你也要能处理的过来。
[34:10.920,34:19.140]  那么使得你的这个硬件要求啊处理的这个结构的，要这个这个处理程序，你的你的分部。
[34:19.140,34:22.040]  反正总的这个大区群核心的处理能力。
[34:22.040,34:24.940]  要达到这个最高分的这个时候的能力啊。
[34:25.040,34:33.280]  其实这个就很难，但是往往他他这种属于有点像这二八原则似的那个最高分只是。
[34:33.520,34:37.020]  有可能在在那那一段时间内。
[34:37.020,34:38.080]  嗯。
[34:38.420,34:40.680]  就就相当于你可能是。
[34:40.680,34:42.280]  80%的。
[34:42.300,34:43.780]  这种东西。
[34:43.780,34:47.460]  就是处理要处理在那个最高分的那个时候。
[34:47.780,34:51.100]  在平常的话，你可能只能用到20%。
[34:51.100,34:54.220]  就留处理他会带来这样的一些问题，当然。
[34:54.220,34:58.800]  也没那么实诚啊，就往往在最高峰的时候可能还会。
[34:58.860,35:1.960]  稍微平滑一些粉啊就是。
[35:2.560,35:3.680]  的颜值。
[35:3.680,35:9.720]  那个时候稍微延迟一点，把它分拉宽一点呢，我可能这样的话，我可能到60%啊。
[35:9.720,35:14.060]  就处理了，平常是跑到20%高分，我到我我蠢。
[35:14.060,35:16.800]  我储存到60%的能力就行了。
[35:16.800,35:19.820]  你要是完全的没有延时的话。
[35:19.820,35:24.780]  那那对这个这个设备啊，对这些处理资源的要求是。
[35:24.820,35:26.260]  非常高的啊。
[35:26.260,35:27.680]  嗯。
[35:27.700,35:31.520]  或者就是往往就到最高分那一段我就。
[35:31.520,35:37.280]  限流了，但是流处理核心本身还是希望，就是他的处理，光价就变成。
[35:37.280,35:52.000]  你只要有东西流进来，我就能处理结果。当然带来的这个服务啊，带来的应用也不一样，就是我实时统计出来的结果，实时处理的结果马上就可以应用出来，马上就可以查询到，就是这些带来的这些体验。
[35:52.000,35:53.220]  嗯。
[35:53.400,36:0.220]  或者带来这些能力啊，都是以前这种批处理的这些，这些系统呢所。
[36:0.540,36:1.940]  所不能比你的。
[36:2.540,36:9.780]  嗯，然后就有了这个流处理的这个处理框架这个storm吗？因为原来能这样处理的东西确实没有啊。
[36:9.780,36:16.880]  那么storms的话，他他当然对流处理，有一些相应的这些概念啦，Stream啊。
[36:16.920,36:17.800]  Puts。
[36:17.800,36:21.780]  POS就是这个这个水源头啊，水龙头的源头啊。
[36:21.780,36:23.460]  POS啊就是这种。
[36:23.460,36:24.100]  分。
[36:24.100,36:27.120]  分叉留着这种呃。
[36:27.120,36:30.040]  分叉的这个这个处理的节点啊。
[36:30.040,36:38.140]  那么有了这样的概念，然后他还有这个淘宝纸啊，就是我整个留的这个处理是有一个拓朴图的。
[36:38.140,36:45.400]  那么这些拓朴图之间，或者这个留的bras节点之间，我怎么留，怎么分部，他还有。
[36:45.400,36:49.240]  各种各样的这个分布规则就是有的是我这个流。
[36:49.240,36:52.580]  要按按段分啊，像他那个。
[36:52.700,36:54.560]  分到下面去，这个就是。
[36:54.560,36:56.120]  他也可以做过的康。
[36:56.120,36:58.500]  就是词频统计啊，那我就。
[36:58.500,37:1.940]  它包括可能做排序，它就要有这样的按段分的。
[37:1.940,37:3.040]  这样的能力。
[37:3.040,37:4.320]  那么。
[37:4.320,37:9.820]  他还有各种方法或者是到达特定点呀，就这些都是他提供的处理能力。
[37:9.820,37:15.220]  总的来说呢，这个storm他提供的这个流处理框架，但是它也是内存处理的啊。
[37:15.220,37:17.180]  他把这些东西都放在内存里面。
[37:17.400,37:18.480]  嗯。
[37:18.680,37:29.500]  然后就是这些处理节点，就拿消息连起来，然后他只要一有消息，我就往这些发发，到这个节点，我一处理完在内存里，我就往下面的节点去分发。
[37:29.500,37:31.640]  就这样的形成了一种。
[37:31.640,37:33.040]  没有延迟的。
[37:33.040,37:34.200]  这个。
[37:34.200,37:35.900]  这个流处理框架啊。
[37:35.920,37:37.780]  这样的话，它的。
[37:37.920,37:44.680]  他这样的流处理框架的话，所以他对这个消息的处理能力是非常高的。
[37:44.680,37:49.260]  那么很多这个流的平台就经都是达到百每秒百万。
[37:49.260,37:52.420]  就是百万条消息啊，他可能都是。
[37:52.640,37:56.680]  都轻松达到这样的这个这个处理量级。
[37:56.680,37:58.100]  啊，就是这种。
[37:58.140,37:59.780]  这种处理能力啊。
[37:59.780,38:2.300]  这个还是核心的话，就是因为。
[38:2.300,38:4.040]  他是在这个。
[38:4.940,38:7.080]  他也是在内存里面跑啊。
[38:7.080,38:12.360]  然后内存里面跑的话，就是然后这些消息他用。
[38:12.360,38:16.780]  他用这个消息的这个流转的这个分部体。
[38:17.860,38:20.300]  确定了我整个处理。
[38:20.300,38:23.300]  处理框架的这样的这个。
[38:23.300,38:25.120]  这个体系啊嗯。
[38:25.320,38:26.720]  那个。
[38:26.720,38:32.000]  或者他也是用这种分布使得它的这个内存处理啊，他用这个消息。
[38:32.000,38:34.180]  消息流啊这样的方式。
[38:34.360,38:37.080]  其实就是我把一个固定的一个出处。
[38:37.080,38:41.600]  分布处理框架的逻辑啊，通过我的留的定义。
[38:41.600,38:48.160]  留着分部，我就在你的这个里面，我就固定好了，固定好了装载下来，我就始终这么跑着。
[38:48.260,38:50.700]  那么这个时候他确实就是西南。
[38:51.440,38:55.080]  会达到比较高，我我在中间我不去。
[38:55.080,39:4.480]  调度我的任务的加载呀卸载，那当然刘也会也会做啊，我可能一个新的流任务，那么我会重新开始在部署但是。
[39:4.480,39:9.600]  基本上留处理的这个框架，它因为认为我这个留消息是源源不断的吗？
[39:9.700,39:12.320]  始终没没头没尾的。
[39:12.320,39:16.740]  就是，呃有头没尾，反正从这开始之后是不会断的。
[39:17.000,39:20.800]  除非我自己把系统停掉啊，否则的话。
[39:20.800,39:24.140]  它相当于就把这样的程序处理逻辑和这个。
[39:24.140,39:27.260]  这个分部的方式我就调度好玩了。
[39:27.260,39:30.380]  整个我加载到这么一个大的这个机器里面去。
[39:30.380,39:33.420]  然后就不间断的啊在楼里面处理。
[39:33.420,39:34.740]  这个是他。
[39:34.980,39:37.200]  或者在这个戏内存里面处理。
[39:37.200,39:43.040]  这个是这个流处理框架啊，为什么能达到这个很高的这个。
[39:43.040,39:47.640]  呃性能的这个原因啊，当然storm它也是有有。
[39:47.640,39:48.760]  有。
[39:48.760,39:50.680]  缺陷的就是。
[39:50.680,39:55.200]  他是主要是还是在内存运算，他是不做不做文件。
[39:55.240,39:57.320]  不太做这个持久化的。
[39:57.320,40:2.300]  包括他这些整个计算过程中，包括对状态呀，对这些方面的。
[40:2.300,40:4.680]  这个知识呢，也是有限的。
[40:4.960,40:9.120]  嗯，完了对这个spark streaming啊，我们已经。
[40:9.120,40:11.580]  前面将spark提到过啊。
[40:11.580,40:14.220]  他就是把那个spot的。
[40:14.220,40:20.520]  那一一个处理过程小变化吧，就相当于我这个ID画的很小啊，那么就是。
[40:20.520,40:25.320]  很小的之后就变成一个小阿迪力，我们来这样发成。
[40:25.320,40:28.900]  呃网上发，但是他这个速度确实适合。
[40:28.900,40:32.680]  Com，这个流还是比不了的，他可以到秒级的啊。
[40:32.680,40:34.240]  这种这种响应。
[40:34.240,40:37.820]  那么storm它是可以到这个毫秒级的这个。
[40:37.880,40:39.180]  这个相应的。
[40:39.180,40:50.080]  因为这就是spot，他还是毕竟是一个批处理框架，它还是有一定的这个任务调度过程，他每一次任务过来，他是要把它。
[40:50.080,40:50.760]  呃。
[40:50.760,40:51.340]  就是。
[40:51.340,40:54.480]  加载到内存里面，他在小片，虽然在内存里面搞。
[40:54.480,40:55.400]  但是。
[40:55.400,40:57.620]  这个调度过程还是有代价的。
[40:57.720,41:0.620]  那么这个代价就会造成他的。
[41:0.620,41:1.500]  就是。
[41:1.520,41:4.400]  就是核心的这个延迟啊不能做到。
[41:4.400,41:5.300]  非常小。
[41:6.740,41:8.520]  这个就是。
[41:8.640,41:10.180]  嗯。
[41:10.680,41:12.760]  Storm啊，然后。
[41:12.760,41:18.260]  到木就是流处理的基础上，再往下发展，啊就发展出来了这个flink。
[41:18.260,41:23.640]  当然flink我们前面也说过，他是一个比较复杂的这个体系。
[41:23.640,41:24.760]  那么。
[41:24.760,41:27.300]  我们只是看他一些啊。
[41:27.300,41:30.960]  所谓的带来的优点，带来的好处，从这个角度。
[41:30.960,41:34.040]  就是来来理解一下就可以了。
[41:34.220,41:35.580]  嗯。
[41:35.780,41:43.160]  他是说说真的来做到什么高吞吐，低延迟，高性能啊，因为这几者之间。
[41:43.160,41:47.300]  会有，会有矛盾的，我们以前看到的技术就只能还是。
[41:47.300,41:50.000]  只能管某一头啊，他确实是。
[41:50.000,41:52.860]  能把最急者同时都能。
[41:52.860,41:53.940]  支持下来。
[41:53.940,41:57.020]  当然，他不是同时工作了啊，他就是。
[41:57.020,41:59.780]  它的底层机制是能同时支持的。
[41:59.780,42:1.060]  我在。
[42:1.060,42:2.240]  我可以处理。
[42:2.240,42:9.560]  这个低延时的这个任务，我也可以处理这个非常各种批量的任务，那么我底层引擎啊。
[42:9.560,42:11.220]  是不用改的啊。
[42:11.300,42:16.740]  那么它实际上能支持实现这种他就是大概用这个流失窗口。
[42:16.740,42:18.700]  的这样的一种技术啊。
[42:18.700,42:21.100]  来来做到对这种。
[42:21.100,42:24.920]  呃，这几种支持他开的那个窗口不一样啊。
[42:24.920,42:26.860]  他相当于在最底层的。
[42:26.860,42:30.840]  这个流调度基础上完了有一个窗口的模式来支持。
[42:30.960,42:34.460]  然后他也能支持这个有状态的这个计算。
[42:34.460,42:39.940]  它能支持非常大量的这个，因为状态实际上保持和状态持久化。
[42:39.940,42:41.860]  是一个非常重要的。
[42:41.860,42:45.920]  嗯，但是也有难度的这个东西，所以大家对知识状态。
[42:45.920,42:47.740]  因为状态你要。
[42:47.800,42:50.320]  快流失处理，要放在内存里。
[42:50.320,42:51.220]  但是。
[42:52.060,43:0.200]  嗯，要很快的寻址到，但是你要想保证对状态的支持的话，你就要有一定的持久化的能力啊，因为你不能。
[43:0.200,43:9.960]  因为你的机器像那个storms的话，它的节点可能重启会容易得多，他不成状态不成状态，我反正我把它在加载上来。
[43:9.960,43:11.180]  那个。
[43:11.240,43:12.040]  嗯。
[43:12.040,43:14.280]  消息接进来，我就可以接着跑了。
[43:14.280,43:17.420]  而你要纯壮，有状态就不行了。
[43:17.420,43:20.960]  你恢复的时候，你就必须把原来的状态是什么样。
[43:20.960,43:22.100]  加载上来。
[43:22.200,43:23.320]  在。
[43:23.520,43:26.960]  把这些消息弄上来，和这些状态来进行。
[43:26.960,43:27.580]  就是。
[43:27.580,43:29.620]  才能恢复到这个。
[43:29.620,43:32.860]  呃就保持状态，这个不出问题。
[43:32.860,43:35.540]  那么它有它特定的这个状态的。
[43:35.540,43:39.640]  这个备份和加载的这样的一个技术啊，它相当于是。
[43:39.640,43:41.980]  在整个消息流里面加这个。
[43:41.980,43:44.060]  说我这个同步的这种。
[43:44.060,43:44.700]  这个。
[43:44.700,43:48.120]  累似家这个同步消息标志点这样的一个方式啊。
[43:48.120,43:50.060]  使得它可以。
[43:50.060,43:52.340]  嗯，就是他的。
[43:52.440,43:54.500]  状态备份状态恢复。
[43:54.500,43:58.480]  呃在这么大量下，还能做到比较好的这个特点。
[43:58.580,44:0.060]  嗯，所以。
[44:0.100,44:7.740]  这样的话，所以它的体系啊，也有相应的这个容错能力啊，他当然为了做到这一点，它的内存管理啊也是。
[44:7.740,44:9.620]  呃，非常好的。
[44:9.620,44:13.040]  嗯，所以他这个状态的管理包括。
[44:13.360,44:16.860]  他的这种就是它的那个备份机制。
[44:16.880,44:19.140]  同样也能支持了这个。
[44:19.140,44:21.200]  这个迭代和这个。
[44:21.200,44:35.340]  增量迭代的这个过程相当于他状态，当然就是恢复，我在这个时候存下来出了问题，我到那个状态的某一个恢复点，把它恢复回来，别再一样的就我程序改了之后，我在之前有一个备份。
[44:35.340,44:37.840]  那么我改了之后。
[44:37.840,44:41.320]  就这样子，我发现这改的不对，我就退回到之前的。
[44:41.320,44:46.600]  某一个备份点，这就是什么迭代铮亮，迭代啊这样的一个。
[44:46.600,44:50.000]  呃一个概念，这些都是非常好的这个。
[44:50.000,44:52.100]  这个特点啊，当然也。
[44:52.500,44:55.220]  他造成的它的底层实现应该还是。
[44:55.220,44:57.340]  还是非常复杂的，但是。
[44:57.340,44:58.820]  嗯。
[44:59.060,45:2.300]  用上面啊，可能也用起来也是。
[45:2.300,45:5.380]  有讲究的，但是这个flink也是。
[45:5.380,45:7.780]  在相当于bug之后。
[45:8.060,45:9.340]  盗墓之后。
[45:9.680,45:11.520]  更新兴起来的。
[45:11.520,45:13.660]  这么一个框架，我们。
[45:13.660,45:16.560]  切，看啊，这个flink是不是能。
[45:16.560,45:19.940]  真的这个一统天下啊，就使得大家。
[45:19.940,45:21.920]  因为各种东西在上面跑。
[45:21.920,45:27.460]  都有好处啊，在这里呢，相当于也涉及到这个。
[45:28.000,45:29.080]  嗯，嗯。
[45:29.200,45:36.260]  呃就什么了马结构啊，这对这样的一些概念，也可以在这里回顾一下就是。
[45:36.280,45:37.780]  一个体系。
[45:38.640,45:45.840]  呵呵，原来的了，那就是认为它不同的，因为我们大的来说的话，就有这样的这个批处理。
[45:45.840,45:49.000]  这个分析查询处理。
[45:49.000,45:51.080]  和这个刘处理啊就是。
[45:51.080,45:52.000]  这样的。
[45:52.000,46:0.940]  三种的计算模式啊，批处理，当然响应可以办啊，你你甚至十几分钟啊有一个结果。
[46:0.940,46:3.840]  都可以，但是要非常大量的这个数据。
[46:3.840,46:6.660]  那么实时查询的处理的这种的话。
[46:6.720,46:7.440]  就。
[46:7.600,46:13.160]  很多要基于C口啊，要这样来做，但是人查到一个东西吗，要有结果的话。
[46:13.160,46:15.500]  他是要有一定的速度要求的。
[46:15.500,46:18.060]  分钟级别的可能是这样的要求。
[46:18.060,46:24.580]  而实施处理的，对流处理的这种的话，那都是要秒甚至毫秒啊这样的。
[46:24.580,46:25.640]  级别要求。
[46:25.640,46:27.320]  那么，但是。
[46:27.320,46:32.900]  对各种各样的应用的支撑，满足原来认为是不可能同时做到的。
[46:32.900,46:36.380]  所以有那么大结构，所谓这么大就几种体系。
[46:36.380,46:38.000]  我组合起来。
[46:38.000,46:43.360]  那么你这样的运用放在这那样的运用，放在这儿啊来进行支持，但是那么大结构。
[46:43.360,46:44.500]  有他的。
[46:44.500,46:48.380]  就是那么大结构，有他的又有他的问题，因为。
[46:48.380,46:51.960]  因为往往这些应用之间还是有关系的啊。
[46:51.960,46:58.780]  我可能实时的就是刘处理消息的统计，我的那个分析查询我也要用它。
[46:58.780,46:59.920]  那么。
[47:0.220,47:3.840]  那么我还要跟这个批处理这些东西结合起来。
[47:3.840,47:8.720]  原来那么大体系的话，你就得搞搞三种东西，因为它里面。
[47:8.780,47:12.300]  嗯，平台不一样啊，你可能编的程序都不一样。
[47:12.300,47:23.860]  那么这三种东西在需求，在有些变化在于发展，你这三套东西又要有维护一致的地方，又要有各自不同的地方，那可能编起来维护起来试试。
[47:23.860,47:28.280]  这个你要做做程序，就知道你外卖做项目啊你。
[47:28.280,47:30.300]  项目更多男的是。
[47:30.320,47:35.300]  当然开始做出来也难，但是你后面发展维护，因为它有不断的需求。
[47:35.300,47:37.960]  项目版本又要走分支？
[47:37.960,47:42.340]  或者一分之要合并，在往后的一个管理是更困难的地方。
[47:42.340,47:48.580]  而那么大结构在这上面，它虽然说我各种需求都能支持，但是在这个管理体系上。
[47:48.600,47:51.000]  其实是带来的问题是非常大的。
[47:51.140,47:52.440]  当然是。
[47:52.440,47:55.400]  希望辅导课啊，当然能把他这个。
[47:55.400,47:58.280]  就是拿一套体系都都支持好了。
[47:58.280,48:4.000]  真的是非常好的工具啊，什么各种配套也不玩也完成了，可能各种应用都是可以。
[48:4.000,48:7.420]  签到这个弗兰克上来，当然这个千一也是有代价的。
[48:7.420,48:9.660]  这个是另说了啊。
[48:10.680,48:14.480]  阿图计算啊，这这就是。
[48:14.480,48:18.400]  一种单列的这个计算，这个我们也说到这个图。
[48:18.420,48:21.640]  实际上是世界关系的就是。
[48:21.640,48:24.180]  呃，这些事务联系中的。
[48:24.180,48:27.520]  更本真的这个关系啊，我们很难有。
[48:27.520,48:32.040]  说这个的一个关系，就是这个单线关系，我们说的这个流是一种。
[48:32.440,48:34.100]  事务在进展的。
[48:34.100,48:36.340]  其实这个事物一方面是由这个。
[48:36.340,48:39.280]  时间啊，像这样的流逝的往前。
[48:39.280,48:47.180]  不断的进展，而且这个进展过程中，这么多事物之间其实都是相互影响的，这是真实世界，是这么复杂的啊。
[48:47.180,48:55.600]  但是我们拿计算模拟的话，已经有留了啊，那么也有拿想拿图，就是表示这种更复杂的。
[48:55.600,48:59.100]  这种相互关系的这样的一个处理模式。
[48:59.100,49:9.220]  当然，虽然现在这个图的这个能力和我们真实世界中这么复杂关系之间能力还是有很大的差距的，但是我们起码能走出了啊，这个。
[49:9.760,49:11.140]  涂到这一步啊。
[49:11.140,49:16.240]  那么图里面当然有些图的概念啦，这个顶点啦。
[49:16.240,49:20.580]  这个什么边啦，就是这是我们这样子来表示。
[49:20.580,49:22.240]  他们之间的关系啊。
[49:22.240,49:28.040]  还有这个什么粗度啦，然后我们说到这个图，最后有这个裴格儿啊。
[49:28.040,49:35.560]  他真正的一个实现的这个例子啊，那个例子里面，包括他是在顶点上唇什么。
[49:35.560,49:39.520]  顶点调用computer的时候啊，参数传什么啊。
[49:39.520,49:40.820]  这是一些。
[49:41.280,49:44.880]  这个就是踏实线上啊，我们能。
[49:44.880,49:51.520]  能理解的东西，它有一个特点，就是顶点的和这个关系他纯，他是从出发点来纯的。
[49:51.660,49:53.540]  就是我这里像。
[49:53.580,50:1.540]  我这边出去啊，像哪像哪些景点有关系，我在出发点来淳儿不是在这个。
[50:1.540,50:4.740]  就是入编这里纯啊他边是有方向的。
[50:4.740,50:9.600]  而入编这纯的什么是纯的？我收到了多少消息？
[50:9.600,50:11.240]  他是拿一个消息队列。
[50:11.240,50:16.280]  来传的我收到多少消息，而这些消息从谁发给我的，其实我不管。
[50:16.400,50:20.140]  那么我收到了，但是这个值，我要处理这事。
[50:20.260,50:22.080]  这个在这个。
[50:22.080,50:23.560]  顶点要处理的。
[50:23.560,50:31.460]  而都是由我发出消息，这边来记啊，我在这里要访，要往哪些点去发消息啊这个是。
[50:31.540,50:36.000]  Pre狗它处理的，当然他整个助理有个大不模型啊他。
[50:36.000,50:39.800]  他用这样的一个大不模型来协调这个。
[50:39.800,50:45.460]  这个处理过程整个一个图的计算，图的处理就是一步一步，这样的走下去。
[50:45.620,50:47.280]  来做完啊。
[50:47.400,50:50.900]  可视化的这个就基本了解一下就行了啊。
[50:51.180,50:54.920]  那个最后的这个应用的啊也是。
[50:55.160,50:57.920]  这个了解一下应用里面就是有个这个推荐。
[50:58.140,51:4.340]  协同过滤啊，协同过滤有什么基于物品和基于用户的啊，这两个有什么差别？
[51:4.340,51:6.700]  这个是要知道啊。
[51:7.580,51:11.920]  行，那么整个这个课程就讲完了啊，那么我们。
[51:11.920,51:13.940]  回头周五在做实验啊。
[51:13.940,51:16.520]  然后希望大家期末能考好啊。
[51:17.080,51:18.200]  再见，嗯。

************************************end****************************************

