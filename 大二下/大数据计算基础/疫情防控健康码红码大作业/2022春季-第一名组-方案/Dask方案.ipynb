{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38371f76",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#2023年春季版本\" data-toc-modified-id=\"2023年春季版本-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>2023年春季版本</a></span></li><li><span><a href=\"#2022年春季版本\" data-toc-modified-id=\"2022年春季版本-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2022年春季版本</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c46f551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dask\n",
      "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m793.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle>=1.1.1 (from dask)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/u200810216/.local/lib/python3.7/site-packages (from dask) (2023.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from dask) (21.3)\n",
      "Collecting partd>=0.3.10 (from dask)\n",
      "  Downloading partd-1.4.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/u200810216/.local/lib/python3.7/site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/u200810216/.local/lib/python3.7/site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->dask) (2.4.0)\n",
      "Collecting locket (from partd>=0.3.10->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: locket, cloudpickle, partd, dask\n",
      "Successfully installed cloudpickle-2.2.1 dask-2022.2.0 locket-1.0.0 partd-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0480067",
   "metadata": {},
   "source": [
    "## 2023年春季版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03bd5c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmax 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:66: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "共运行时间59.81107069924474\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "cdinfo = dd.read_csv('cdinfo.txt', blocksize=100e6, names=['base', 'time', 'inorout', 'telephone'])\n",
    "# cdinfo = pd.read_csv('cdinfo.txt',names = ['base','time','inorout','telephone'])\n",
    "# pandas will not read successfully, even if it can be read, it is likely to crash in subsequent processing.\n",
    "\n",
    "infected = pd.read_csv('infected/infected01.txt', names=['telephone'])\n",
    "infected_list = list(set(infected[\"telephone\"].tolist()))\n",
    "cdinfo_infected = cdinfo.loc[cdinfo[\"telephone\"].isin(infected_list)]\n",
    "# print(cdinfo_infected)\n",
    "\n",
    "# convert to pandas dataframe(because it is small dataset)\n",
    "cdinfo_infected = cdinfo_infected.compute()\n",
    "infected_base = list(set(cdinfo_infected[\"base\"]))\n",
    "infected_base.sort()\n",
    "\n",
    "# If somebody has stayed in a polluted base station, it is judged as a red code\n",
    "redmark_df = cdinfo.loc[cdinfo[\"base\"].isin(infected_base)].compute()\n",
    "redmark = list(set(redmark_df[\"telephone\"].tolist()))\n",
    "redmark.sort()\n",
    "\n",
    "# write to redmark.txt\n",
    "with open('redmark/redmark01.txt', 'w') as fp:\n",
    "    for item in redmark:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "# superredmark:\n",
    "infected_base_time = cdinfo_infected.groupby([\"base\", \"telephone\"])[\"time\"].apply(list).reset_index(\n",
    "    name='infected_time').drop(\"telephone\", 1)\n",
    "\n",
    "# For each polluted base station, record the corresponding polluted time period through a dictionary\n",
    "# The reason for using a dictionary is to quickly find the value by key and avoid brute force search\n",
    "infected_base_time_dict = {}\n",
    "for index, row in infected_base_time.iterrows():\n",
    "    if row[\"base\"] not in infected_base_time_dict.keys():\n",
    "        infected_base_time_dict[row[\"base\"]] = [row[\"infected_time\"]]\n",
    "    else:\n",
    "        infected_base_time_dict[row[\"base\"]].append(row[\"infected_time\"])\n",
    "\n",
    "redmark_df = redmark_df.groupby([\"base\", \"telephone\"])[\"time\"].apply(list).reset_index(name='stay_time')\n",
    "\n",
    "# The following code is temporarily added in the formal experiment to solve the problem\n",
    "# that the same person has been to the same base station twice\n",
    "stay_time = redmark_df['stay_time'].tolist()\n",
    "fmax = 0\n",
    "for i in range(len(stay_time)):\n",
    "    stay_time[i].sort()\n",
    "    if len(stay_time[i]) >= fmax:\n",
    "        fmax = len(stay_time[i])\n",
    "print(\"fmax\", fmax)\n",
    "# fmax=2, which means there is not a person entering and leaving the same base station twice\n",
    "\n",
    "# new df from the column of lists\n",
    "split_redmark_df = pd.DataFrame(stay_time, columns=['start', 'end'])\n",
    "# split_redmark_df = pd.DataFrame(redmark_df['stay_time'].tolist(),columns=['start','end'])\n",
    "\n",
    "# connect two dataframes\n",
    "redmark_df = pd.concat([redmark_df, split_redmark_df], axis=1).drop(\"stay_time\", 1)\n",
    "# print(redmark_df)\n",
    "is_infected = []\n",
    "# Determine whether each person marked with a red code can be marked as a superredmark person line by line\n",
    "for index, row in redmark_df.iterrows():\n",
    "    flag = False\n",
    "    for i in infected_base_time_dict[row[\"base\"]]:\n",
    "        if i[1] >= row[\"start\"] and i[0] <= row[\"end\"]:\n",
    "            flag = True\n",
    "    is_infected.append(flag)\n",
    "\n",
    "# redmark_df[\"stay_time\"][0]<=infected_base_time_dict[redmark_df[\"base\"]][1] and redmark_df[\"stay_time\"][\n",
    "# 1]>=infected_base_time_dict[redmark_df[\"base\"]][0]\n",
    "superredmark_df = redmark_df.loc[is_infected]\n",
    "final = list(set(superredmark_df[\"telephone\"].tolist()))\n",
    "final.sort()\n",
    "\n",
    "# write to superredmark.txt\n",
    "with open('superredmark/superredmark01.txt', 'w') as fp:\n",
    "    for item in final:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "print(\"共运行时间\" + f\"{timer() - start}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc1920",
   "metadata": {},
   "source": [
    "## 2022年春季版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04027d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmax 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "4 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    954\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m                 \u001b[0;34mf\"{len(content)} columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 4 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58037/420970245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# new df from the column of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0msplit_redmark_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstay_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;31m# split_redmark_df = pd.DataFrame(redmark_df['stay_time'].tolist(),columns=['start','end'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    698\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m                     )\n\u001b[1;32m    702\u001b[0m                     mgr = arrays_to_mgr(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 4 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "cdinfo = dd.read_csv('cdinfo.txt', blocksize=100e6, names=['base', 'time', 'inorout', 'telephone'])\n",
    "# cdinfo = pd.read_csv('cdinfo.txt',names = ['base','time','inorout','telephone'])\n",
    "# pandas will not read successfully, even if it can be read, it is likely to crash in subsequent processing.\n",
    "\n",
    "infected = pd.read_csv('infected/infected03.txt', names=['telephone'])\n",
    "infected_list = list(set(infected[\"telephone\"].tolist()))\n",
    "cdinfo_infected = cdinfo.loc[cdinfo[\"telephone\"].isin(infected_list)]\n",
    "# print(cdinfo_infected)\n",
    "\n",
    "# convert to pandas dataframe(because it is small dataset)\n",
    "cdinfo_infected = cdinfo_infected.compute()\n",
    "infected_base = list(set(cdinfo_infected[\"base\"]))\n",
    "infected_base.sort()\n",
    "\n",
    "# If somebody has stayed in a polluted base station, it is judged as a red code\n",
    "redmark_df = cdinfo.loc[cdinfo[\"base\"].isin(infected_base)].compute()\n",
    "redmark = list(set(redmark_df[\"telephone\"].tolist()))\n",
    "redmark.sort()\n",
    "\n",
    "# write to redmark.txt\n",
    "with open('redmark/redmark03.txt', 'w') as fp:\n",
    "    for item in redmark:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "# superredmark:\n",
    "infected_base_time = cdinfo_infected.groupby([\"base\", \"telephone\"])[\"time\"].apply(list).reset_index(\n",
    "    name='infected_time').drop(\"telephone\", 1)\n",
    "\n",
    "# For each polluted base station, record the corresponding polluted time period through a dictionary\n",
    "# The reason for using a dictionary is to quickly find the value by key and avoid brute force search\n",
    "infected_base_time_dict = {}\n",
    "for index, row in infected_base_time.iterrows():\n",
    "    if row[\"base\"] not in infected_base_time_dict.keys():\n",
    "        infected_base_time_dict[row[\"base\"]] = [row[\"infected_time\"]]\n",
    "    else:\n",
    "        infected_base_time_dict[row[\"base\"]].append(row[\"infected_time\"])\n",
    "\n",
    "redmark_df = redmark_df.groupby([\"base\", \"telephone\"])[\"time\"].apply(list).reset_index(name='stay_time')\n",
    "\n",
    "# The following code is temporarily added in the formal experiment to solve the problem\n",
    "# that the same person has been to the same base station twice\n",
    "stay_time = redmark_df['stay_time'].tolist()\n",
    "fmax = 0\n",
    "for i in range(len(stay_time)):\n",
    "    stay_time[i].sort()\n",
    "    if len(stay_time[i]) >= fmax:\n",
    "        fmax = len(stay_time[i])\n",
    "print(\"fmax\", fmax)\n",
    "# fmax=4, which means there is a person entering and leaving the same base station twice\n",
    "\n",
    "# new df from the column of lists\n",
    "split_redmark_df = pd.DataFrame(stay_time, columns=['start', 'end', \"start1\", \"end1\"])\n",
    "# split_redmark_df = pd.DataFrame(redmark_df['stay_time'].tolist(),columns=['start','end'])\n",
    "\n",
    "# connect two dataframes\n",
    "redmark_df = pd.concat([redmark_df, split_redmark_df], axis=1).drop(\"stay_time\", 1)\n",
    "# print(redmark_df)\n",
    "is_infected = []\n",
    "# Determine whether each person marked with a red code can be marked as a superredmark person line by line\n",
    "for index, row in redmark_df.iterrows():\n",
    "    flag = False\n",
    "    for i in infected_base_time_dict[row[\"base\"]]:\n",
    "        if i[1] >= row[\"start\"] and i[0] <= row[\"end\"]:\n",
    "            flag = True\n",
    "        if i[1] >= row[\"start1\"] and i[0] <= row[\"end1\"]:\n",
    "            flag = True\n",
    "    is_infected.append(flag)\n",
    "\n",
    "# redmark_df[\"stay_time\"][0]<=infected_base_time_dict[redmark_df[\"base\"]][1] and redmark_df[\"stay_time\"][\n",
    "# 1]>=infected_base_time_dict[redmark_df[\"base\"]][0]\n",
    "superredmark_df = redmark_df.loc[is_infected]\n",
    "final = list(set(superredmark_df[\"telephone\"].tolist()))\n",
    "final.sort()\n",
    "\n",
    "# write to superredmark.txt\n",
    "with open('superredmark/superredmark03.txt', 'w') as fp:\n",
    "    for item in final:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "print(\"共运行时间\" + f\"{timer() - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d436a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
